{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing various methods on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cubic_newton import CubicNewton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO29abAk2XUe9t2sfXlV9fa93+t1ZnoWDAaDdUCQBAEKJEGCtikGKIkCLTgm7JDDlEMRJmj+kBHhH1LIIVmOkOmARYqQRWEnBQgmCUDDwY5ZMTPd093T++vXb19rXzPr+sc5Wef0637oZQbdXeb9Ijpe9a2szLtl5jnnO4ux1sLBwcHBof/g3esOODg4ODjcGdwD3MHBwaFP4R7gDg4ODn0K9wB3cHBw6FO4B7iDg4NDn8I9wB0cHBz6FG/qAW6M+Ygx5qwx5oIx5lNvVaccHBwcHG4Oc6d+4MaYCIBzAD4MYAnAiwB+y1p7+q3rnoODg4PDfoi+id++C8AFa+0lADDGfB7AxwDs+wBPp9O2UCi8iUs6ODg4/M3D6urqlrV2dG/7m3mATwO4qv6/BODdP+kHhUIBTz/99Ju4pIODg8PfPHz605++cqP2N2MDNzdou84eY4x52hjzkjHmpXq9/iYu5+Dg4OCg8WYe4EsAZtX/ZwCs7D3IWvsZa+2T1ton0+n0m7icg4ODg4PGm3mAvwjgqDHmoDEmDuDjAL721nTLwcHBweFmuGMbuLXWN8b89wC+ASAC4I+ttadu9zzfOfVvAQBeLNJrG8rFAQCzw9I2kGwBALqWLDedICUnCWgYcdPtNaXiPgAgm5NzRON5OkcnQX+7FfnO0PHJqFiGPL6WaYll6MwZ+s1XvrlO5x+Ufnz4AzMAgJG8TGvgBwCA7Xq717ZSb9B5s/Tb3KBoJp3IJn2nvIMqxRgAoF2X9+2j478BjeNL53qfIx4dP5gf7rUlk0nqT9DqtRmP+hmN0HwU8kO972IerYFR7/j85BgAIDGS77V5A9R3P6Bxbpw40fvuwve+DwAYGpV+ZCdpjvK5iV5bYpiuawdoPgJlnMsUBmlMI0J++wkaX6Qra7tc3gUAvLq0BADYqTZ633UjNM5kTvodS1C/L/7nr2Mvjj72XgDA7KT0+9wPvgcA2Nos9dpSKZqjkXGal5Wy7KeTr5+l73jOAGB3cwcA8OCxQ722h8eoT8srq3T+tuzhQxk6/5WyjCWRpLZD2WSvrd6iNS3y9RPqXvID2tdd/gsArTatVaMlezLO+z7h8f3VluPrrQ4AIOgGcl7+27XS38jcQWj8h3//xd7nGOgc/+Dvf7zX9rd+43foWsXlXttn/t2XAAAnXqC984vvf2fvu8NHHuD+FHttH/pVug9qG3KOYPUSACBdGKFr5+Z7322ubwMArpw9K8fXyLQbNJq9tuxABgBQqtC1ak35LpOj/frAYzLeE2fJd2NDWYmHH3w7AODIkWMAgNbi673vtoplAMD25navrVXbor9puQ9vhjdDYsJa+xcA/uLNnMPBwcHB4c7wph7gbwWyHr/VI6qNhAwkIiIFxPg4Y0j68oz8IBYnCTLSleM9S298X0k0QZckDhvQ30hUJBAToeOuYWG7/L+2iIRR3/L56f+2o67Zobd0mvsIAIYln6jSDlos3V5YIikq5subPDNJJ+505VVuWSRNJvdfrnQ60/s8MTkNAMhmReKMRqlPWroNmIdOZgcAAINj473vmhskLTZ3ROKsVOhzsV3tteXHybMpliWJ9kpJJIp1lrqyVmk1rIm0MnKOWIPW0uP1aatF6IZ9zCR6bYk4zV86JlLooTEacyabBQCcunip991SiSVjpdU0/A72QyxB520pqctjRSSVkLUtpOi4eIzWxfdFQg21m0ZdNJ5qvXbNmAAgwl0y/DcSkzW2hi4aj8jx2Qi3JWU+2tw5W6Fx+kpStl3ad35Hxhv4vBe7sifjltYgDRpf05Pv/Ch9F6ib1LLGZX5CHImvNpvhPbBTqfXaFtY26NpbS3LeCknS731iDgDwgfc82Ptuev4oACCZFa3XdOl81ars091d0ljSAd1DsbpQc9/41l8DAE69Jt7OkTiNuVQrq77T+BJpulZMjX0gRnu9bOUe3WVJvRrIcTunTwIAJkZIoh4bHel9t7pF+39nR/ZHJpPF7cKF0js4ODj0KdwD3MHBwaFPcc9NKHGPVI6Ip7rCWlm5qVTSGKk5yWRoQlFqOas3VhlAmi1SARt1Oa+JkNdjMyCVKjUg5FCUVcGUiUsbq5iRtrRV2vTO6/Llu1qD5HNEPHkvemw6ianjNpdpXCdeJd/8g0dELX9yjNSoji/EpmmTmhhJ7K+uTs3M9D6Pjk/SNRNyDi9KKndHmTMsk13JfI7OnxMVLh1htTmQNbi4vAAA2K0KWXfcHAcAjARE+G3u7Mo4WfXv7O702g4xwZqPi4pu2mQ6SUSpvx1P1NCgweYuORypgNcgKY02Qes8Fu6Tg3O972JLRBBeLInZphPffy5fP/FjAMATjx7vtXls9oiqPdao0/nieTJVVZW5pMPmFE/thYE8EbLxhJh+goDHwGRgUnXLcNtgSo5PsjnDU3PkmeCacwXalMN7uKvMJWGfVBNG2NR38BDN29WmjKWxSPF6HXV8h483aj72SoPJVK73Oc7mNG1SarfIZJE0Yqr6nb/3MerHwSkAQCo10Ptuh9evrW66oEFtG0Uxf1zaoM+REvXx8tKLve+ef/VlAMDuruzhTIrMj1W1T8P1mz94GABwdWtd+l2h50bDE3NQlWNc3vXOt/faUl6L+0j9MWkZS7NJ/Q4CMf10Ed6v8ry5GZwE7uDg4NCnuOcSeC4kJDyRGiLMEDYC9cr3SeKoMxdjfSEP45be4J6Vc9Q7LAFB3M+WXqEfFyt0/PwTQgSNTNNbtWmEmIh0SZqLKkKnwtKLz+++Rkv6UamRtBh0RaJuePRWfe6MSBnPvUoaQJ3dCSslebt3KiR5dH05B6p0Xk+LQMJP0n8L4nrkxWhcJi5vcr8necuSD7BbXZxdpmot0UjqdZJQlkubvbZLWyTJthUBONckKSTFhw0rV0TLkv3yFcm48No6kVQjuzLmmRFyKcwlsteNJcp7oKPc1QImEttRkbo6GZJS03ma76GEEF0Pzx0AADRUPzbZNU5GJ2jWSDrqKkm2xRJWuSKSW5f3W3qEyV8lbedZm4l4ovFUi6SdtOsiuVkmmtNMpGklK8a/1VJ8SBq2G7JPmzXaW6GUHVFiWUhoaok9VBu7qi3dprXPgs4x98CUnMPQXF25uNpr85h1NTcMyCa89ymRRo8dJA3x0Iyk88ixe2csLZrf+AStvc/31W5bJNQWawVpdfwqa3zf/P5zvbZ4hrTB2UG61sXzC73v6iWa+05d9nqN3TBHh0VjWF2jnbFw+QIAILCy52dGScONKEeK9U3qx9VlIWQ7TAiPzpMmlyqIW2o7RvdmJ66eY4O0Fzq1/Qn2vXASuIODg0Ofwj3AHRwcHPoU99yEMpgjVbfriUpj2Be21ZXuddiEUvVJZWs3lerBZEEsKmaHlk9mAduWtoWL5wEA2ytrAICtdSEVHn03EUzTR0WHtR6bZpQJpcFd8plEbSun5Z0qqav1lqiVF1ijeumMirhqNLi/4YVEVQ8qIfEh8wH2cW3WlQllGtcgOyDqX5PNJXUVWRYE1M9cSmwvXY7Eq2yQWrmhiJqzFymyc0FFuO20SG0f5uhIACh1qC3L5pqJWUmPc4g/bzyw1WtbfOMMAGB7YbHX9sIqmTYSbCp4tHug912O/dvXt8VkcDhD8zWeEVNLu8LmBkuRj+kh5a/NvryPzIpZ4OwajfUyrsfIKKne9YqYaFpssmgo012KFzDk05vKNFLdpfUeVFGr7TKtY6cpa2u7tAdNO7QNyn7ymSk/eXGh15ZIkHnscRXNGZpOLJszumo/ddiEElPmktAN3EBU9XVuW/vLZwEAA48e7n3XHKI5DSLar5vP9xPKCfx3/+1/rf5He213Te2nVfo8dkD2zE6RiMRCiuY5MyAmlwrfEyfZrAEApy6SI8ClRTnvzCyty8YSxQKEawEAYNOZ0d4Hcb6XlZnOC01w7FyRjMjx9Q7do5q0TnGkcyeq/MUHybQW+mJUlQm07dHxp5dkDTIcea7X5WZwEriDg4NDn+KeS+BgoiYWE8LNY5IqASGiWqHrGEvgxpO3VITFgG5XvY8sfY52hTjwA5L0opbenKWrIqFe8kiqzEQlWiozTqRNNK7cAhPUz0SKyNGmynESRqrtVmQsp96gCK2GkuaiLLJ1DUlTgcpTUWNJL6jJeS1HBLaUS991iCh3yTCqT7WlWaLwKzLm9askGdfr1LdqRQijM5zboZ6TsXQHOIdMVsjfqqV+NrK0ZjWVN8Y0aI0ePPxAr21+kqTgs5cu9touFonUXVslaerFRclTMTpO65F6QNwkN6JEMkbLMkdpUJ9KoTicksjUBLvhjabFHc8fI8nuB7geoTYTqOjFkEhMJcU1MxX1+Dv6f6cmWkLUUN8OTgvhtr5Ac6kjJUOX08ucw2WtJPvkyaMkBS8sCXmYY2L4sUMitXY6JJmGLp+RqOzXKO8B7xpJuct9FGmxkaLfRObIjbBsRDtdXyZtJWiLxNnl+3FuSHK9CH1HsFb29dYW7bWdbRlfsUTnG47JWvkcPWljNH9VRTb+6KVXAQCvnBW9ybJmkYiIxnWJ926Z3TvbSmvKcUGZbk3O2/DpniiVZf1STJQafj5pEnOb3WgHlJvk1CxFU2+WRQuLZGl883NEeuYzci+9tk3zsaX2cKPFpPhtiNVOAndwcHDoU7gHuIODg0Of4p6bUOpMVEa7opaHLuHJiKi8MVaRC3FSgeJKHfY4OVWzJVGAdSZyonExoXSZeAnYvGKNqFYlTsV57nVRc44YUqNGJiZ7baPZRwAA730HqX2V+lrvu0yWTDRvXBaCbmVd+hQiJEBDsimSkLGHia7gyfgsq7oRiAq7F/FBlQo2zkmWBoVs7CVoUsmpyqdI1Qz4/KeXpN9tTh7l5YWEC/h9n1Nqc4av0WVC7+wbklG4UCVCKoiI73QySdeqpWReCnn2tx8n88pyUtTVE+t0juymEGi1CJlQIgPSj2EmA+M13tKbQsiODPGeUeaPsYhKR7wHfpjEKi4mhtDfOZ5U0aqxMMFamIJV1ieZpLl65GGZv6vLw/ydrG1o/guJzXZd1idgUq2loxfj1LeoikSOcdRsGJ0ciahIViZFWy05R5ioqaH6y5ZJZBK0rwOdWIlNbLGYyHtxjuytrmzIcTkhnwGgWBTysM3paet1MeH5TIpvLEgq5EaEHRImaD2bDTFJnD1PppNSVc0HxyTs7sp+qvK93GLzpqciX6OGfc99IRSjGdoLI0OyVqHZrcWE5e62jCUkqz11jkKO1ramklPl2azTWifj0ulXJKlWaZk+H5yXBHJeSBLfRp15J4E7ODg49CluKoEbY/4YwEcBbFhrH+G2IQBfADAPYAHAb1prrxc1bwE+S+AdlZy/HRIBHXmbpaP0liwM0Js5oaVzzl8SjbZUG73GoiofSH6QpIqtldDtSr2/6tT9zrJI5YXCOwAAc6O/0mvb4IT+9QZJHoWMSB1TYxR5dur0H/faWpznQ7t2Bdy3WJre+Ece+sXed6MT7LJVEwmoy1GRQeu6inU9ZEdEGq1wBGFyWAhZw2RPcVuS4SfzJJkusfvgcxfO9L576tc+AgCI5yWSNcwfMTkthOL6Oknty4tEStZakm9k/Sr19+K6qvPBeTvsgMplk6DPVXbxgoqI87r0+dxF6VssSdd/+Lik4Q2atD/aV2l8kTWR4ltMHpkRkXYi0f0l8IAl8GhK1iDGbpJFX6S0AdCe8TmlsC540K6S1JqOCzH2wFHy/Wx2hSAsszvbyChFo2bSoo0ZXsfBIVkDjws6lFoiyW6we+J6kf621X1TYSI2GpP5zrDG11ak6wRHv1rOu7N06rXed7kp2ltHHnu41xZShmf/32cguFYCN4o55cy4aDXlmltXiKzeOPdqr+3hY0cAAGMFulajoqJhyzSWVlHO0eV1GcqKpn14jDS5OLsVN9tCFIYRnhN50U6jrBFpDWNkjOZjiyM9000Zy6HMIJ9DtN4UayzD+aO9tgzn+6kskjvj+qWF3ndJLtrwxMNC8Fd3RGu8VdyKBP4nAD6yp+1TAJ6x1h4F8Az/38HBwcHhLuKmEri19rvGmPk9zR8D8HP8+bMAvg3g9+6kA4YlhE6g3OYaJOm1q/L27UZJukiEtu2sSCCRFL3NIjGRXrrdKvdf3Jbmj5IkcZkDetoNkdLa7EoUDURiTyZI0stlj6i2y3wtkpjinvQ7ESH7YT4n0vBVFj1MVGePo8+jk5QjIV+QslHGkiQRT4uE6HOQUwciZezN4lFXNs7QtQpK8qhXaD5qa/KW394mLeLlNyjx/Nxjkn2vwyW2okYkjwPz5Lq2tiqawNULZL+MRzjoKS1bqsbukYmYjCXOxTdsXDSosKpBKkfzNz0jknX2bSStrq1J5FJmgPPQqPw58RQHQbRpvZsLkvckFQZOTatsc2OinexFPEV9jENsnOucGyOtSu4lD9B65Nn17riVNa6tUPmsalWk7aFpklBLu6IFdbn4x9TbngAA7Jx+Q8ZZoLn8+H8jZciiSZLGv/rF/9Bre+Msayds++6qfieSNKe5Qdk7DQ4oMTGV8ZJtw/VF2t+HsiKhJllLXlwQLqNdI0m9rtwN9+bQ01kRazX6bVSVexvk3B/lFblHu9y3q4vkZnfxjBTmKK/R+s2OSzm+4fF56seO2KgH2LU1l6HxJRVfZrmcXF2V3GszJzCQF3fGsDDIhTW6r/IRkbZHR+m4kYJoilusSVVUwE80ERbC4OIyKh3N5AHaCzlVIKQV0HFdlT/nZrhTG/i4tXYVAPjv2E2Od3BwcHB4i/FTJzGNMU8bY14yxrxUr9dv/gMHBwcHh1vCnboRrhtjJq21q8aYSQAb+x1orf0MgM8AwNTU1HUOMh6ngk2rPAEDTH7YpLxfWuxS1SiTatVQtSiHmawoqDqBcUOqT6clORLyI6RazR8ndXL1gpgY0CX1JaJycS5ypfcAQtSMTRKx+cBBcidcvCIE3fde/AoA4OplqT6dYJMBdHGFCKeS9KmP58/8sPddJssETFLIsg6bQjodGcuBGSG2gGujNBNMyrRVlfQdTsof5uMAgFdPEnm00yF1+J3veo9ck32Z1pbFTdKySeTEyVd6bVkusDE+Ra6WQVSWOBGlcTZU3pqA1fzxOSG8hoZpLK3QZUzlA9mtkGpcrIn5o1ij88VUBN8mu9pV2KQzsqmiKNtc8EOZbZrx/bd+LYyGrIoq+2iOc5YckhwkkaM0huEJiuo8pPKTFHfIJJJNyXWql8g8MTok5owEFyzYYILLqjqcLXZjLSuy0XCa4bYqPJIapLn3eO9aXT2+Q3O5uiz5aNocSWhVpGmRI4VTXNSgrtZnmp0KYspxoMOph9uKTN1bS72qon47nDPIUxGTYYGL6qrssZUVuv76SYo+rZbE3DQ1SaYTY8QkV96g/Rz35N4POH9JIkNmsqAt/djhqvSduow9JPhhZa12tmjO20UaZ06ZQEOzr66BGu7ZclXMQTXep/USrUtHPbNSAzSGqHrehM+Khq+eSzfBnUrgXwPwCf78CQBfvcPzODg4ODjcIW7FjfBzIMJyxBizBOCfAPinAL5ojPkkgEUAf/uOO8Cufzn19htnCTWSkrdeiavBX+F8BWuKtKhw9r0DWZFyEyzFD2SkrdkhIm/6IEk2k2MiDcSZHPVb0o/nX6JSTFsVeXN+9PCHAAAPPkRm/0pNSMGVTZJym00hGJOck2OnKAEJXdBbvVskxWVnTVfI5vJmUZF2eon64yI1PPXkb0MjpqrSJwdofEWVoa2xTZLN0lXJI7HO2kx+msaSygsps7tCEtDakmS4OM+uZYEq6JAbIKnIS+S5HyIdeZyHo9QUD9OAAzoqVZGK2gFJWXWWDCsqJ0s8RmPfXBMlb5iDh9bXRTrbWKXPy2eJoJ7xhVyrxen4RSWF5gb3JzHrXNABKuvi4EPk7rWm3Pw2LpO0/8IL3wEAjI2Jm+Lhw1RNfXBU2rBAhNy2Kt21fJpc6dYuUx6YiCrU0F6juS9/5wUZCxOgdV1BnYOAPA7MyaggnxRLo2kt1bEE2TYiv4X5WcY4N0u7Kv1o8X21/Ya4ctY5l834kJ7Hn4GGrwqy9DImKpExz/loVhaFFD95jvZdp80BN+oJNZEjTW19VfZTmBUxn5f1juSov+tVDvJZFk20zIFE3ahIz1HW3AdVuUHDczl1mLSlmCIbV1lLiPoymOU16vd2R9YlP0j38PAI7aNUQbk0c8GPuLpvd7dZY70NCfxWvFB+a5+vfuGWr+Lg4ODg8JbDRWI6ODg49CnueS6URBiVqFKfhllhA50elkm1eNjWFj/Oq6ukvmxBTC4ZJg1nZ5XPaJZUsAirjlu+qLINJooyeSGYjhw6BgCIpiRa6sAk/XYgS/2ZmxbV6vAUkVirdqHXtsk5FNqKMAp9wsPR+b6qZh6Qmh9R6lxYMcDz93/fplXOklAzrqkK8SE5dnFZTCi5aVJ/c4eJsLp4QVK8Xj5Ln0sbYiLqtkkVHRwWuirOVeADG+Ouigklw8TfqDIHNTiqdGdTTCJhfpHxSfK7H8hLEv8Y+3pXt5XfLltYzl+RsbQ5L8X5DTJflVR59wTX/BzJSb87aTGP7EWbCe2zVdkfK2Wah9dPSd6OGhOyi0sLAICP/fp/2fvubY/T/nv5xed7bd//7nepb0UxEe1s0jWal8iEYhVpF2HiPqqp/7DogCopH+HPMb5HfPVdhXO4eCpdcztMkarMQeAcKJ0yXX9gXOW7GeGUvoclHmJ1kSJwg2B/dd+qAglJJrtHRiSvUJTtKRs1GWCxTf0MSUlt6tjiuqHtw3JPJzhNshmQqNldjuko8r039IiYVwY459LWjsxzhVO6GpW6Ns81dcs1vjeNPJ+2WpyjxlP1cJsc8apST/tMnnp8v/u+jHNznfaplxTzTlTlsLlVOAncwcHBoU9xzyXwUY/ejt1A3k4NdlfrqGxfJSYfAk4Sn1ERcfUKvf3KqrjCBidg32rLOR6dozf3DEeA+Vl5u68tE/nQ9uRtPTpBkmlNkU4Ll8n17uRZIvTSUbmmFxBpeHBKuwySZN9UYwk4E14sRlJD0JE3vx/QZy2Ahwn607m9jlqCRFquuc2RkoEqqdZhcqzYEOkvNhGWKyNp+OJZkcBtg0txqdJTKb5GTLn5gdct9PHPDQgpE+ccJ4WkSOU90joiEl6uMMHjI0mvowoBbK9T37ZWZI4unSTXzWklJSaznAuFpeeFuqxZNmDNYU6iORtpWee9CAnyqHJLnR2i4y9uiOZQGCFtLeTqvKhIuZYXcHVNijFYlrCskuY6XEotzBCoS5/BhMcrOSsatskGifB6xFmbtUoC92xYPd6q47koipLfPHYjTHA0c0MXD2FXt8IhyfMRSrep6P5SY1Y5EISFKMpFIfleeJncbdeVk0CEc+9EmUxtGdFOL3MhluScSPEjB+ge2vXkuDpXdY8fo2vOHJHI3kaR7onNZyXi1YR5TgKZjxLv+9VNOr6u8q+EGjxUQQyfc7JEIjKWsNJHnaV5T+XfuXKFNJh4RrTT2Yk9dRJvAU4Cd3BwcOhTuAe4g4ODQ5/inptQBqOkDtV88Z1ud0jFK1ckNenVHfqczJPaElUVstP8HtJ0SoNNJ+vrorKhzYUUDpDqPTkqJoncEJkWgqioMQmPjmt2JbXmqdd/BAD48ennAABHZyXF5mSa+jg+JmrRUJ7OEYtJP65s0RiSHHXZbMjY/TKbCjydcJ7UxImZJ7A/ZD4qnHgprtTxdY7AbKvanIvniMjZbDOBCyFk01E2l2RF7Ytxop66SpLVaJDqmh6m66cUMeYzcRuJi2nh4PxD1NuujrakfjRLRLouLYrZ4eJJIg23lK9wmMPqqcckCdjMLKe4ZTLpuVdlzRbY9/3hQExK6Z+QNX+A085GlZkuzrUU5w6qCEX2750bYXOMEbPDDpulWipS0W9yAqiSmHcC9ucOo4+T0etNI1AmpTB6UowTEnnJxdURUXJZgh2pkynZky32cY4aRXYyyTh8hBKarStf/FSGxpdRRUOaOTJDFob3N+uNjQsZ/dJLLwMAvvrVb/TakkO0/9tZVTyC57DBRRN8ZUr0wghtFe24fZX2blTdL20uFNHltLo/XBOisFWnubSKOE1FaDarEdnXzWGuwZuhv6WSPIvGknRPL65KXMH6CpHQTz52rNcWOlAceZDakilxNGgxoVlSRHlHJde7VTgJ3MHBwaFPcc8l8Hj2KQBAu/29XpsBJ+VXuQNCEg6DJCn4bZ2qko7zldthWOYqosjD7S2S8F7nN/TgoLhFHTjEkZVdVaqqTVJLtyKuhe0mTVmKfbuiRt6aSSYwoippVyZD5zuscpfUwmukRrnfQtD1Mkl6Ig1PzbwfADA29g4IqtBoVCTSs82EbyEtko3PEm9M5ZxJcvnrSU6tmgpk7AFLslD5aAI+R1eRcGXOGzIyya5pNVVMYIuki2RWxp6P0ZgDVeDi1Akihrc3KfKwqCQmU6L+xlV02mOPUpTjOx99pNc2PUGpbsO8KqUtcRNb3KZ1rxXFrdLP7Z9Ac+UNkvofzsv81S8vAABmazLvg1wkYSJFfSyfExfDixxpurUqaW3DaMeZSdlPuQytc2yE+m07IhmG5fUC5YIagItHVFVkL0ewesOkETSU5hXlAiiFA1LFvrJKZHvMylpF+FEwM0lEZWxT8pMMDNGatdX9WGeXu8S4Sgu8B1/+yn+Uz1/4cwDA9OzhXtvIUZJQdzOy1ztddibg9Y4qDTCSZddCNR+1XXYBVBpdl10bA5/62EwoF15+RqQUoVhPs2Y+LPOWnSBpuWVpbiMb8p1t0ecz50/22tJcKjCuijwUpinN8PRhckP2m9KPDt+HtYbsdSvTcMtwEriDg4NDn8I9wB0cHBz6FPfchDJ6+L8CAFhV2WNt+T8DAKrNK722SILrGnKF6UZTzA67rBKE+0YAACAASURBVGbrSiSxNOkjc1NCKgzlKVLSMt1ZLco5ECN1f+yASnLToPdb9byQJin29T04ReaXfFYRf4bU2qmsqFutFB3XVISsZRNRrGeGEdNF15CaOjr99l7b2x//OwD2Rqa+CI1KSUgnkw39zEVNHB8ncnZsaq7XlhghlbQUpXnTRGGM/XsTaSEgu1xPsLgu0ZlNJl7K2zS+fEFVoBklNTSvEh5960cUmVhUSX9Mis4xEPpyt+S7pKX1HswJATQ7TWNJJ4QwbXIk7bEHyLzym78pKXy+9AyZ59rKtFUriollL0rbNL5IRvZH0tLn9KCYciKG9kxjk0jjzKys2fAo9e3SFWVOYxIrCSE2N3lNO0wURlQ1lgjvtaby529xGldfVSPy2WQw8dCjAK6dqwyT/blRIRRzE0Qedmpihgmv0GEfal/7+jMxXVMV6Ls+jcvW1D20B1/43J/3Pj/wIJm7fumjv9pra7Cf/Wu7qkoUk+JdHkJkSMVUZNiBQZX+6XbYhKKuWw+Te7FpJJtXlbp4WM2izGmW4yEOHp3qtWU4tevSRbonvIrc5yef+zEAYHdL5uO9v0JVJ0cnxVTV5jq/m1u0n+Oe3L9pjqmwKuDDi9z+49hJ4A4ODg59insugR95nCTUoQlV/fxHFEG1fPX/7rW1kxwpxrkGbFJew01+0wV1IVneMf8YAODDT/1Or21yikjAdkBv+WpF0q1eXPomACBqF3tt2TRHY6m6kLAUgZbIkaTiGXmTjxXoLV1WRGjRJ1Koq6q7j8dIWt0uXgAANFS61VSBpIBHHvsvem0zUyS9bJSurYOp0VDpPwsHSEJNdaQfiQzNqReXSMkKk51t1iIW1sUt6tghcstL5YTIq3JK10DNR5Pd5LpNkmhNV9U2DWicrZrSDjph3g4h0AbDCuEsoUxNiaveZJIkx+K29C3FOTH05k1ylGOMo+M+/Asflj4maOwnNiQFcaNSwX4Y4fwa8auiAXaYoG4NiXQb4TS4XXZZnUjJfEdbdH6/JZrXFrsWIhCpdSpF85tmzaut8q0W6/Q5qQjfeJLnLy3HVdhVcPUkubi2lcvgNJO661tCnIa5eMrKbW10mL5v7zDBqYpfjHANyvqKuHdOTHKUclXmUWaG8DM/I2vwzveRs0JWaWgJS3OT3pC9Wwpv4QF2fxxWGi6TmGlVjMNwvhVNipsKzW+UicWhYelZmYucZAdEsn+Aa5UOxUVS7+xSR8bGSKM7uylRyt+5QlJ5KiX30gRrhfGktKWStO9aLY6Uzajzc3dbqihENHr7LKaTwB0cHBz6FPdcAs+N0NtpfFbcb7wsSZ87XZH+zm1QFe5ahKRW09V5COg9NByXHAnvO042qSHVlknQ238wRtcaGxCpZISz+V3ZEam/XiJpxEuJy5nlbHoBBx4lVL6HKBcAuLolzvnVgPqbGpKgk+m5nwcAnDpFEtvKkrgjvfNJqo1x7OC7em0dznrWgMqzsAcNZd/NxikQZWtTpNYdltCLyt1wo00SZJQrbkeURLEbSvQxkSonZ+YBAFMzUjrswjmSTDoNdm/zVSEAdrFUXmIY5KT8VuXEKK1zIBEXajh0SHiLM8+Ti2FXnfdxzrdS25F5Hp+hMaTjtB6ekoSmx2kPPHdxodcWjTAPgesR5gPZPCma0WmW+gdYMwGA47scbFLnMl1LUmquWidpeHtK8nCUIzQfyZjSFJ8kyW2IuYYzV0Q637hMc5Qeln2a5QyPcaWBDpapn8ll2q9+TDSkAlc6r1+80GsLpdW8yrEy0CRJtsCazJLK8XPhdeJbpvIilSfnSVN87XUp8rBXAn/qAz/f+5xid8ZTZ6Xc4Ow4rVF6V/iIbc6IGR2iR1OtruzGnDdE51/J5+gcSRVAlmySxpeK03HpqDxHwjQxQ12Zv+wGzUfSE87okTlyd5zk4KXWmtw3Hsu9MaUJ1JinSGXkWkPM/YTBVCrdE8IYqkZT5jmXk+vfKm4qgRtjZo0xzxpjzhhjThljfpfbh4wx3zLGnOe/++fndHBwcHB4y3ErJhQfwD+21j4E4D0A/qEx5jiATwF4xlp7FMAz/H8HBwcHh7uEWymptgpglT9XjDFnAEwD+BioViYAfBbAtwH83u12IOAalNGUqJUPHiO1KBoTIu+l8+Se870z/xwAsNER1W18koT/9059pNeW9EIXHomEy09RHo4I1wmMqoJ7kTi7+wUf6LWdvkLV6GtNVdvPIxOAiZNKldR1JH0yr7RUPotWjepdxquiKmWmiZib4JqA8KTf737HrwEArCpOsVQj0mSrebbXNqNcqQAgpsZS3SCVuloWtS8bupEpl8VMilS20HRx6YqQdnUmuPyWqLdjoxxZNieuiDZOKmOFU7BWiuJaVeWK8qmMzFE+y5XCxSIC5powO0+E7+q6nOP8AkU3PvmkuOiN8ry1N4VAa3C18dQImbssVE1RjiCsN2U+/BIdrypW9vDw40SAL6maopfXaW4K6hzH03St6CJFLdbGRR5qcNRddVsiGs0o751AFq/DqnyMc+akxsWEEtmiPXNVuW2ePEumkLmDYsZ66ACZM2Jt6pt2p52c5HqWZ2ROQw/BmHJLfejDP0v9KdN8txdelj4mieSbbsm9tHiaao/WV9VC4t3QyA4Kcb+6QnN57ryYckolus9NVUju8hWqG4pNOu/QlCj2ba5LGVPmozq7FhoVsZkJ7+8qDbS9pUj0BhOhA2LwibG7oW+EcG4NEcn+xjb155nvfqf33dQszUerrIpvsAtgIiWmnDANdFiMxio3QsvPp2ZbiOR85KdMYhpj5gG8HcDzAMb54R4+5G8Ym2yMedoY85Ix5qV6vX6jQxwcHBwc7gC3TGIaY7IAvgLgH1lry8aYm/0EAGCt/QyAzwDA1NTUdSng1pbZfaoh58sX6POhOZEkBnLkAlisklT+Wl0kiqkHieQ5kBQn+vUNcnmanZXsgh3OgVLmcmyeKok0yMn5B+KSXbBR+SEAoFK+1GuLhK5GnNkur6MKApJ861ak7S4TRqmOuCdG20TkjI7MU/+nPyTjZElsvSYEWrFBUsvG+jNyrdxD0CiVVGBMkSSxQLmkhe/2lCpS4HNukCiHQUzNCOFbZYk26cn4NliyD2JCEE7Ok+YywK5r2yonpMdBFlBrW6qS1DI9JoElNk3b0LchESTr8uRTjwMA3vvep3pt07Mkca6de6nXtsXBXBGW9iODKsCE8+FkB8SFrSFb6zp4XFjCf+R4r63Apb2OHJFcHi3OijdcI0mzmpC5KsWJ/EqmRaryea90dmVt105SpkT/eyTxBrMiWddbdM3nn5egrRLnQLm4INqS9yGqLz7KuVASTZEkq8t0HxiVFdFjF7pkTgKsxh6kdTzzfZKsYxHZJ8Nc/KJWk7agS/dEVJHie5FICMG/vkaaSFGN3WdSt1sXTSrJgXqrSySxB2Xpd47dCKfnJOBmgLXdBESSDTXLBudIsir/zxiXTEy3lOwao31a8kWi/uYPaB4uL5P204nJ8dkh0jq9rrgAHjhAUnlK7YFQ2/VDCVwV2uj6oVao8rSYn1IgjzEmBnp4/6m19s+4ed0YM8nfTwLY2O/3Dg4ODg5vPW7FC8UA+CMAZ6y1/0J99TUAn+DPnwDw1be+ew4ODg4O++FWZPanAPw2gJPGmFe57X8G8E8BfNEY80kAiwD+9p104LnvkHqYHxT/yYeOkxr50NuEiJqbJqP/Bx79RQDAoFJpumvkO1pZlEi7FkdDxpKixjWqpL6lM6RqlkuiunU6oSlH7PTVCn0OutLWqIT+w6QOjcRFjcpyWtGhghAklk0Q5bL0o9WktsIomSxSMamyXeNK1g2VI2FtlYoTrJ070WvD0WtNKM++Ij7IaU5Fm1UqbIqJwlxKta1TfzdWSc0ujCtP0JAAbYvVy2O/4YXLor4n2WQxnCPVtKkiJqtt8pX3V0RtHuK5f/z9D/Tazm+Qunxli9TVR97+oJyf87mQEki4cI7V29PiU9zOkukpmSXzTtASE0orRb8dnJR5jpc5ErQuKnqI1AiZ3cYfkz02x9OQTEg/SkyUmkfIb91TZgdvm9TyuCcmpaVVGt+wUr3XdqgfuyX6bSYr5qOzF2mcJVXAIJWm+SiqOq3f+y6Z+n75V8iUMpkV0rj4PcoD092Se8Nwfc/u+4WMvvTstwEAqxfJ1NFdkKjLrZN/TW1PvK/XljHUj9auEIR7kVDRnOtrNHadgyad4/lTBR2mHqF93Rig+ahXxRxk2DqxWBFTRO0y9bOrooPD2qRJLiRyeETWPRWj+d4qi0kz2aI901JFIaoB7f9IntNXV8XUsb5Cc3RkWiKGPTaTRBRR2WW2OODvPCUvW6456ivzjmduP67yVrxQvo9rc8Vo/MJtX9HBwcHB4S3BPY/EXFkk17izZ0TK2NkiKW5oRFz65o/Rm+ptx0mCGyuIwP/at78LALjyyud6bek8EZpBVySaVoOukcmQtBhJyJu/xOW8qsWFXlu9Sccb9WbstOl86RTnqUiLu19mfB4AkFA5DbwWSatL2yL5Wp80jOE4SUDVisryxi9kvytv/O11cpnsNPfPoPfjlaXe55EsSVjHxoSUTLE0NFQQKXsmTse9XiYpp10QienQHEUcXrkq593eJYlaZzRsMKm2xRrPxAGJokyUSPqcNjL2ySFy3Ds4IoTz2NQ8ACB3hTSpfEzW5fICkWVrGyLZnz9LxzUWpG+xIzxxZ8ltUyd2az9GUl2yIWOPMWHaUS56IeocVbe6Kt8tM6nmRfS6sIsg5+PIZYUkHeZ5NqpsWZ1dxrSzmMflvPAwEXM7StsLpda8ykeT5yjU3aKQh6trNA9XFmmvzT0sRGtgSZL1FJHcXiPtpKwk2RPP/wUAIMvam6nK8ZfTdNxAS/LXDOxydsbq/p5lKaX99vJ8qJwl25xbpdRSJOYwa3QTtE8mM/O972KcqXE8L+touLDLmWXlAsuFHAoZ1sZGRCNZTjBRrtwOc0z+6syKtRXSWFaX6LmwelY0nlEuxBJV0naTMzsGKrdJh4nvUJm2yvEjYI2/q7I+GpeN0MHBweFvDtwD3MHBwaFPcc9NKJkEEX6JuKg025wo/fvfFv/rao1U+tFR6nJuQN49YQ78nZKo2SZOvrltFekUi7JfKKfz1FW5AyabKmUxZ9SbdLzniQobZRIkGiH1yIuL2hyaZNqBTGupRQRKxQqxmY3Qbzy2l5SU2SZokKpZMooozJOqPq58uPfiwqKQMueYCG0eFaLw8aOkVseVGjfGtSpzbEJJGvFhHeCkPMOjKuEX1xFMKpJs4gCtS36KTCJTirgqVzlBknK6jnBGH68ubTOjdI7c46Q2L23IWBYuUBTq5TUh4eodusaVihCEow36vLBAftXveofUDx0YIJ/sbEkISzsU+q1fjw7PX6spJoMWq7yrCwvSD06TW2eSMfDFXHfsGEWVjitCe2qc/K7Lymf/hxyZOM6mqG5U5qXBxQ2OHhOTSDbNxB/EvFPhYiFXr1CkpH1MfMkPfJwKKCRUZG91k80DZ8/32sqW7pPBBO2JlbrM7YpP/XjfpPhfezNkRku/ooj1PVBlKvHww1RsIqKSZKU5AdVXvvilXtvSqTcAAJk8mV9y46qeKkd2jh+U+ShM0P48clDiCGsckRqaROLKv3qEfdo1eb14kZLJXVURwLtlWts46D4Yiks/Cjna/9uKSC5y1foD0CQm3WuWzSS+Mud2Wly385rImFuLrdFwEriDg4NDn+KeS+BtdrGBEQkhxa5aVy9JmtXqDhEekxwtODsvWSzK2yRR1BvirhbjPBydjpAKYb6Qrk9vaNNR0Wk+SUWlsrhPdVhCNnGRTBOW01dyYv14VKISA5/GUq2rxO2GItzGZsU1zmfCr9niUlw5kXKvlkiy2ql/v9dW4JJjfkLmaC8WryzINbmidxDIG9+PUN/MoERAPpAj8mZoi/NU/PhU77vWNM1zREWW5QdJeskkRFvy6yztcOrYrXWRSporNJa4yoIb5VSg3ZaKQAtoPjIsHc3NHe19V2Ei9AffFzdJcDmqjiKMnlsk6fPdH6CcHmOPiwTe6HIq2JRoS36SOnUjCXx4iObFe0hcNcfGad5WllQ+kEUiU8+fpX26tSF75xJHSi5FZM2Gh0iK00Gga1xEI8oEpEqjg2iS5nloWKS/NK+HryS3JXZrK7GLXsSTfZ1mV9WhUXF5G4twqcCLouGWlric3q/TvNkrsofrr9H4EmmZP48jY21j/xTHVongMzOkZdUqMkeDHBE6odLlJpnI29wgabi2I9rKsrcAALjyquRBSmZojtIDoiWnWEtps0a0ogo1HGMX5UhcZNfFZZq/8qa4RLY6tD87luZ7tCB73vC91IFaBHYXjkR1LhSOMGa3UWtl5X12IwzUHBlv//t7PzgJ3MHBwaFP4R7gDg4ODn2Ke25CmZh/GwCguCOpO7sdrnqjUpkuXqQ0l8us9V18QyqdBFUirqzynfY4ci+ifCvjMVJROg1OfborCnQ7IPVpuyRERpvJh65RNQlTRGAMhBF/qv5luUnHV1QVEcPReYkBIVkCroHZZVUsPypjuVr7AV27eLnXFtaKxE/wE63VxJc2VNRKbSHhVrh24QtbYmaamCUyaJ4rh2xcle+23iCVPqXMR2VDa5RVFc67TDaVymQOGpKpQmuJCLqoMo+NjtG1aiqFaJ5VS8vjGxyR6kwHD9Lc1EuSqcFvsu9xQua+Curn8Q/9HAAgUL7CrS2ug5gSNdvyb8UgIoiw2SOvUgWHlV+mpoTIe+g4JT575zspQvH8BUn3e/p1qly+tCjreInT02qpyfDattnU11VE11CSTAEDysTW4URsfqASI/GKVzkp1InTQoAvvkYjPDI332ubPUpzGjGyP9KWIw9P0RjiNVWrkddbLS0iU2SaOfTBD0rfqtemQ9ooia96oUBrul0WX+svf+kL1O+yOB9kuXZspk1z36yJn7nPJs1mS/m0cwX65q7c+za8A3jbDQ/J/AU1+q3ybUA8Rte8cP60jIXvnfERmqvhvKxLuUnzPKwiPCcPEIlvVIS4x+bCKD8j9N3b6LLp8Ro/cGdCcXBwcPgbg3sugc/MhS5BYvwv7ZAE0awLgdHiN+L6CqVjubr6au+7UY5UM57EuA0W6O0YSt0Aeilgq2UiLXwVFbbBLojllrxpDbsPRlUkZpxzcyQ5z8huU+Vf8em4TlcIjzpHaHme5HQYyBChlOCafR0VieY3SWLyG+Ju1WzT3HSUC9ZeRCIilXT9UFJRqV2ZeDyzIK5jB5jUfdcM5f744Ljkuuhycvmo4qhSnOpzYFoI5ItFIip/fIbytUweFRcvDBPptbu1Kf3ktK/xddG4cjs0H/nhsDq9jGXuILmrPfiwuESucQ3F7aoQpjEmpXY5V81mUbSJRISk87SqkxlJ7b/18/nsdW0dJrWCjohuBZbKB9lVcGxC5uXxxykN7sqKjPPMG0QSL5wXEm6b87+02XXRKG2lXiXpMpcX7S2bpTW4dFlcLQMmrbe36Pgv/CdJOxyw1JpS0t0gR3NOqpjQUZ/G8LNRkpQf+Hu/2vtuggso5NMSWekNkNTaHBFNYH2PBP6lb/2o93m4QL9dXxOpf6NInz1FtndLtKZhluaU0jrDvCEqK2tPgu2q/DK9ihVMEOr7/NGHSeN/8EFxKvjKn1GC1YjKp5LltfWiIWEp91KUn1WHDkrUcY4jbz1VrzOyR6LWKbjbHNF9DXF5B7lQnATu4ODg0Ke45xJ4o0FSg36Bttv0iu105I04MEySWCd0yu+I9NVq05s/rgoNDA+R3c50xaWqtENSWaVErkzJvNhya+yS1lVFEExvetR7jrsUWOp3pSESmW9Jkk6ogJsuS1R5ZUvOJTgbXIck08ruQu+7ndVz3G8JADEBV4339pfAo+rNb0I3RZXbwfK42kkJtHmO89BM56i/j8yIRFEYJg0mojyl8pzrIzsj83YgT5Lx3CGSok+q6ucnOFPddEbWxbJNM64CYvIFOl+Ms9KlfRlnjAODjjz5zl5bcI7c90oXlIbBQUbldZrT9rzK4FcgyTiekLGnYvuXr8qxhOr7Wv1g1zSVD8Tn4J6Qo9BrkOUx55Ut/sDsPABg6wkpPXaF879cYvv5xvpK77sil6l79tlne21P8jyUVbm8Dvezy3bxWl3Zg8Pq58rlbZcDf654ih+K03wsshvr3A+/2/tuIEZjHynIuicmiAsYKIiL415c2RCe4+Iy3aNWZYnMDM4DAKrb0t9SlbkUzl9SUFXeWzz3kWukXB6n4gQ67Nroc0EME1PZC+vUp4gn81Er07NkclzuuTBHSYyzIiZU7pShAeJxZmZnem1x3qeeChoy/NwIFcquchlstWnv6jxLsfj+gXr7wUngDg4ODn0K9wB3cHBw6FPc1IRijEkC+C6IZYwC+LK19p8YYw4C+DyAIQA/BvDb1tr9dfx9sHyVCMuWKqTgMZkQVSpFF0SCjEywGtcQl601PkcuLzX+smlSh2wgJpRdNp3UKqQyNVTugXKJVLeuUt8N6z7atavdrnIb9S0eEbW8WiQfR68jxGZigNSseEwVj2hR/oigTepycVOi05pcvd6o/CthL2OeqHHXQRWA8Nh/qquiUBtcnCKZE5X37BKZa168TGr8YELU/S6n/xwcEFc6y45kTeWemMySi9bbn6TIvB0ra/aN18gta2VVzF2PF+h8UVX4IXdpAQCQSpKJploW1XujSPMdHRKC8OBxmpuuyp+T4PS+odocdNRW7IkpMkfRn7D120z+dlXkXIxNLkllHmuwShyqyhFFSBlW0aOqAEQqQv3OZ6TfE1wb9KEHHwEArK/LXrjIZpWFS0I8/9Vffh0AUFVumMG1CTWuIctCDd1TYw+3SqDYwCaTqCdeIzL69ROS4yTB92GhIPfX8DiZ2KZV1Ow73iY5WOgCag18jmz0Va4XS/d0qysRnmHxlGo54L9F9R2dbyAn8xe6dybSch/G89TfkCj0fTHRfOuZvwIAfPMb3+i17XCxC085AjTZPDY2Qn2Mx4XAnZ0l18JBlZo5znPkXRNNSecLXZmtIlNb7MfoKZLW/pRyobQAfNBa+zYAjwP4iDHmPQD+GYB/aa09CmAXwCdv++oODg4ODneMW6nIYwGEPnAx/mcBfBDA3+H2zwL4XwD84e12YH2FpD9NQI6FhQgGlQO+pa4W2d2vsiNv1SZXmx8bne+1eUws+W2RAupNIn5qLfpb3FDl0zgQRecPCd+INtCkEJEwnLwNMVW1vcpaRNAWaTvLhEun/APph+HsdZb+Nrsy9kyaXPoqNZHEDBMkHe0/tQdBoN/FoRuVtJQ5T8bgmEiyQZQkn9dYQja+5J55d5ek7MdUAMgAS+VBRcYc4YyNmVGSLg8eFne/Aa56vt6UOX2Vs7atNIRkjCzTbyMsgW+p786X6XPXqBwTKRrf5LwEQHU5iKvJ+6RjtRRKn68JoLH7Szs1dv2ECrIImIROxOWWCV03DUvqxso4o15w3Tks/1afIxSWkyzBDSlScGaatLejxyQnywKXWVtdlWIWW+ymWeaiJK2mEIVdlvq6uFZKp2vrjJ7mmv6YqJIMed1biijcKZIG0PBFO9grgXdVwpZQm7HKVQ/s2hqJS+BWlwnIGq871P0YLmAvkAtAq0LrnkzJnkyxVB5jN13bFi08yu6xZVWIIry7fVWbIp2hvZtNk6ZxYEY0jUMH6fOA0k7D80YUMYweecn7Q813s0nPpVhMWRm616/RzXCrVekjXA9zA8C3AFwEULS2t2OXAEzv89unjTEvGWNeqtf3r97h4ODg4HB7uKUHuLU2sNY+DmAGwLsAPHSjw/b57WestU9aa59Mq0AABwcHB4c3h9vyA7fWFo0x3wbwHgAFY0yUpfAZACs/8cf7oFGnnxWm3tVrizGZNjklRF6a/TEvXya15UJRItwiMUo1mkmJKtbmnBE6yiv0I601yGSwU1GpTzm1bEdFpwXsO219VbmcTQsISD1rtuUdWA19wpWLcY7rWMbrUkF9l6P51lt0YK0uxEeH88AMJ4SkqnF0XKupEjjswY3Ur4gis2pcRGB4TPI35IbG+Jo0pjcqYvoJU4hmVKX1xASpqQOqOAC2aHx+nkjjdEyu2eCK4leuLqs2UvPjykyyvUOa2WEmdrq+qOIlrnofVWk6Wy0eq6fNINQnE9ZeVOqqkHqqJqG9ubqqjwg4/WerJWaE8LyZDJm4uirdb4vV/LryyfaZwDOqlqLHpoowYNjryneFKOcFUb7Q01NkVtlVkaZbm2RCWVuje2lpSXKhbLJfebUiZKDfI3jVCHksESZrUyp1bCZL92N6QEi7JK9LQvn4XweVJ8jwTdHVZib2L/dyQo5GLE1Eu0brHagoZXBMR7cjJHqdzRN1dW9EucBGGJ0bMzqlNFe7b0pbvRaawGSeuxEa12aRjh+syKNypUzXsmmV6yVHwumAMj3FewQlzUNcfefzcykRVw+L7v739364qQRujBk1xhT4cwrAhwCcAfAsgN/gwz4B4Ks3PoODg4ODw08DtyKBTwL4rKEkDR6AL1prv26MOQ3g88aY/xXAKwD+6E46cOXqCwCA0dGHe211zoESV+W55g/S5yRXhI5BIvNe2X0OAGCVO1WTK8oHbXlLVjjKq8WugNWquLI1Wfozikzt8pszaIvtPiSnOm16c7ZVtGiLpeC48p6qVkKpUqT9NthdrkbHb6uSau0O9XdkWEmcnB+iVdMS5/ug4d0gk1lMRX+GuTaaVcnJkuLIylaTxjJ2SCTfMy8+T2N5VTQH71E63wMqX0ecK6dbXqqruyIZhi6ily5JRr6Q8PNUbruiT+eoHiJSclK5j0Y4KUbEakLs+gT5PfItjJQN5Pw+R9l2PJWtsrs/iRnhggfaHS+Mcmwr18zw+5CU1MUvwp4ZtT8il0D7cAAAB/xJREFUns/nl/mzTLL3oimVUBzl4zzVD8+j/ZlS5shRJqaPHCMCeUeV+lq4RJGxa+trvbatTZrv4o7sf5810CjnE0qo4hdJlrwHBpWbLpcVCyXxG6HeUJpr6LoYaHdGWmeb0odx9CLvAduS6MigRXvXV/dj6CasC4SAidBwr2lFI7AsvRuRfGNxuoaXkGtZJlZLPm3ss4uiMa5VyPEik5VcltkMu1oqbSmXpTVKspSdTsm+XtmgsYyrkoWN9u1nI7wVL5QTAN5+g/ZLIHu4g4ODg8M9gIvEdHBwcOhT3PNkVmubpIa8fkpM6AcPfgAAkM2ISloYoa4ODVPbgYNCqJx+gdQ4nRi+G5D6Uq1IW6VGCXUCJiJrKtlTaEKJpUW1sqx7BS3l/sjqdYkrucfTolI3Q/W9oSIgGxyRFxHyJp2ja2SZyNhuitmBT4ttlYTLZ7W9LtaP65DOXk8meYosC00KtR0hs6IFTvfK1de3lZ/vAz/78wCAyz9+udf29Vdf5uOlI0c5MX28QfP8jVclze/yMpGXEUXedDldb1dtvTr7A5txIlUTefGFNkxq+S2Zj9BX30KbUDitKEfdNarKdMbkbCcmJjltTtmLcpmOT6evj3zV/uNhrUOfiUpt6gj19oQ2q3RpLLp6fZhEKsosZr0ue7LDezKqEm+FxzebQuSFJp94nOu1psS8MjhIpoCqKoxQLHHxkh2JGC6XaF+EY/dVzEGEzRmJjJgYMpykKzsgppa9GMnppG70V5ulvJ4pTmwcPkdbWt6vHWWGaTc4CtqXsXs8l1ZFW/biNtjsZnX8BEdKalI8EtZ4Tci8xTjxWZT/alI3nF/FN6PZpnGt+7J+m2Wec76+pwncDn3nq+R5PsjkuP+MXg8ngTs4ODj0KYy9BXeqtwpTU1P26aefvmvXc3BwcPj/Az796U+/bK19cm+7k8AdHBwc+hTuAe7g4ODQp3APcAcHB4c+hXuAOzg4OPQp7iqJaYzZBFADsHWzY+9zjKC/x9Dv/Qf6fwz93n+g/8fQT/2fs9aO7m28qw9wADDGvHQjNrWf0O9j6Pf+A/0/hn7vP9D/Y+j3/gPOhOLg4ODQt3APcAcHB4c+xb14gH/mHlzzrUa/j6Hf+w/0/xj6vf9A/4+h3/t/923gDg4ODg5vDZwJxcHBwaFPcVcf4MaYjxhjzhpjLhhjPnU3r30nMMbMGmOeNcacMcacMsb8LrcPGWO+ZYw5z38Hb3auewkuSv2KMebr/P+Dxpjnuf9fMMbEb3aOewljTMEY82VjzBu8Fu/twzX4H3kPvW6M+ZwxJnk/r4Mx5o+NMRvGmNdV2w3n3BD+D76vTxhjnrh3PRfsM4Z/zvvohDHmz8NqY/zd7/MYzhpj/ta96fXt4a49wLmiz78G8EsAjgP4LWPM8bt1/TuED+AfW2sfAtUB/Yfc508BeMZaexTAM/z/+xm/CyqDF+KfAfiX3P9dAJ+8J726dfwrAH9lrX0QwNtAY+mbNTDGTAP4HwA8aa19BFTA8+O4v9fhTwB8ZE/bfnP+SwCO8r+nAfzhXerjzfAnuH4M3wLwiLX2MQDnAPw+APB9/XEAD/Nv/k9+Zt3XuJsS+LsAXLDWXrLWtgF8HsDH7uL1bxvW2lVr7Y/5cwX04JgG9fuzfNhnAfz6venhzWGMmQHwKwD+Df/fAPgggC/zIfd7/3MAPgAu2WetbVtri+ijNWBEAaSMMVEAaQCruI/XwVr7XQA7e5r3m/OPAfh3lvAcqOD55N3p6f640Ristd/kQuwA8ByoIDtAY/i8tbZlrb0M4AL6oOLY3XyATwO4qv6/xG19AWPMPKi03PMAxq21qwA95AGM3bue3RT/O4D/CVKmcRhAUW3i+30dDgHYBPBv2Qz0b4wxGfTRGlhrlwH8bwAWQQ/uEoCX0V/rAOw/5/16b/8DAH/Jn/tyDHfzAX6jKrJ94QJjjMkC+AqAf2StLd/s+PsFxpiPAtiw1r6sm29w6P28DlEATwD4Q2vt20GpGO5bc8mNwLbijwE4CGAKQAZkdtiL+3kdfhL6bU/BGPMHIBPpn4ZNNzjsvh4DcHcf4EsAZtX/ZwCs3MXr3xGMMTHQw/tPrbV/xs3roYrIfzfuVf9ugqcA/JoxZgFksvogSCIvsCoP3P/rsARgyVr7PP//y6AHer+sAQB8CMBla+2mtbYD4M8AvA/9tQ7A/nPeV/e2MeYTAD4K4O9a8aPuqzGEuJsP8BcBHGXmPQ4iDL52F69/22B78R8BOGOt/Rfqq68B+AR//gSAr+797f0Aa+3vW2tnrLXzoPn+a2vt3wXwLIDf4MPu2/4DgLV2DcBVY8wD3PQLAE6jT9aAsQjgPcaYNO+pcAx9sw6M/eb8awD+PnujvAdAKTS13G8wxnwEwO8B+DVrrSp2i68B+LgxJmGMOQgiZF+4F328LVhr79o/AL8MYn4vAviDu3ntO+zv+0Fq1AkAr/K/XwbZkZ8BcJ7/Dt3rvt7CWH4OwNf58yHQ5rwA4EsAEve6fzfp++MAXuJ1+I8ABvttDQB8GsAbAF4H8P8ASNzP6wDgcyB7fQcknX5yvzkHmR/+Nd/XJ0HeNvfrGC6AbN3h/fx/qeP/gMdwFsAv3ev+38o/F4np4ODg0KdwkZgODg4OfQr3AHdwcHDoU7gHuIODg0Ofwj3AHRwcHPoU7gHu4ODg0KdwD3AHBweHPoV7gDs4ODj0KdwD3MHBwaFP8f8BdH4yYSb5SkYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deer  frog truck   car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b28958b8801b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-50f9d4816fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "inputs.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward + backward + optimize\n",
    "outputs = net(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.9941e-02, -3.3772e-02, -3.1841e-02, -3.4591e-02, -3.0901e-02],\n",
      "          [-1.9609e-02, -2.7802e-02, -3.3511e-02, -3.6392e-02, -2.8297e-02],\n",
      "          [-2.1353e-02, -2.6860e-02, -3.0885e-02, -3.2315e-02, -2.5988e-02],\n",
      "          [-2.1561e-02, -2.4204e-02, -2.7912e-02, -2.9007e-02, -2.7536e-02],\n",
      "          [-1.8519e-02, -1.8329e-02, -1.6934e-02, -1.6320e-02, -1.6889e-02]],\n",
      "\n",
      "         [[-2.7803e-02, -2.7821e-02, -2.2375e-02, -2.5680e-02, -2.2917e-02],\n",
      "          [-1.8756e-02, -2.3082e-02, -2.5605e-02, -2.8568e-02, -2.3137e-02],\n",
      "          [-2.0126e-02, -2.2502e-02, -2.5295e-02, -2.7502e-02, -2.3472e-02],\n",
      "          [-2.0268e-02, -2.0463e-02, -2.3401e-02, -2.5388e-02, -2.8975e-02],\n",
      "          [-1.5066e-02, -1.4279e-02, -1.0783e-02, -1.1162e-02, -2.0505e-02]],\n",
      "\n",
      "         [[-1.1899e-02, -4.8356e-03,  3.9895e-03,  1.5781e-03, -7.3949e-03],\n",
      "          [ 4.2124e-04,  1.1501e-03,  6.0460e-05, -1.5368e-03, -6.9260e-03],\n",
      "          [-1.7890e-04,  3.5090e-03,  5.0711e-04, -3.1024e-03, -8.1075e-03],\n",
      "          [ 3.6528e-03,  4.9737e-03,  2.9276e-03, -5.6085e-03, -1.6365e-02],\n",
      "          [ 1.0944e-02,  9.7711e-03,  1.5035e-02,  5.7663e-03, -1.3789e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3382e-02,  2.4074e-02,  2.5938e-02,  2.1298e-02,  2.6352e-02],\n",
      "          [ 2.0055e-02,  3.8524e-02,  4.6612e-02,  3.7485e-02,  3.9829e-02],\n",
      "          [ 2.5813e-02,  4.6738e-02,  5.2242e-02,  4.7865e-02,  5.0292e-02],\n",
      "          [ 2.5265e-02,  5.3676e-02,  6.3066e-02,  6.3271e-02,  6.6994e-02],\n",
      "          [ 2.6274e-02,  4.2001e-02,  5.1934e-02,  6.0192e-02,  6.6708e-02]],\n",
      "\n",
      "         [[ 4.9596e-03,  1.2918e-02,  1.2450e-02,  7.4940e-03,  8.6126e-03],\n",
      "          [ 1.1755e-02,  2.5961e-02,  3.3158e-02,  2.6071e-02,  2.3053e-02],\n",
      "          [ 1.6805e-02,  3.4443e-02,  4.0822e-02,  3.7320e-02,  3.3911e-02],\n",
      "          [ 1.5003e-02,  4.0581e-02,  5.1924e-02,  5.2071e-02,  5.0172e-02],\n",
      "          [ 1.2972e-02,  2.7507e-02,  4.0325e-02,  4.5888e-02,  4.8326e-02]],\n",
      "\n",
      "         [[ 2.0395e-02,  2.4624e-02,  1.8989e-02,  1.4781e-02,  9.2423e-03],\n",
      "          [ 2.3841e-02,  3.4444e-02,  3.8954e-02,  2.7529e-02,  1.8853e-02],\n",
      "          [ 2.6521e-02,  4.1053e-02,  4.6909e-02,  3.5902e-02,  2.6105e-02],\n",
      "          [ 2.2939e-02,  4.5748e-02,  5.9152e-02,  5.0106e-02,  4.0010e-02],\n",
      "          [ 1.9495e-02,  3.3902e-02,  4.6903e-02,  4.2720e-02,  3.7842e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7869e-02,  1.3624e-02,  1.2343e-03, -4.0028e-03, -5.6689e-03],\n",
      "          [ 5.7155e-03,  6.8678e-03, -1.5065e-03, -2.3223e-03, -6.1091e-04],\n",
      "          [-5.4643e-03, -6.6023e-03, -1.9468e-02, -2.0393e-02, -1.2806e-02],\n",
      "          [-5.3791e-03, -6.1635e-03, -1.6084e-02, -2.1647e-02, -1.6167e-02],\n",
      "          [-5.7833e-03, -7.6357e-03, -1.7832e-02, -3.0308e-02, -2.3318e-02]],\n",
      "\n",
      "         [[ 1.5290e-02,  1.9806e-02,  1.2378e-02,  6.6160e-03, -2.9075e-03],\n",
      "          [ 2.1909e-03,  8.9851e-03,  7.4490e-03,  5.2824e-03,  1.4494e-03],\n",
      "          [-8.9039e-03, -5.4166e-03, -1.2294e-02, -1.5254e-02, -1.3153e-02],\n",
      "          [-9.9295e-03, -4.5790e-03, -8.7758e-03, -1.7160e-02, -1.8622e-02],\n",
      "          [-9.2789e-03, -6.6397e-03, -1.0979e-02, -2.5874e-02, -2.4778e-02]],\n",
      "\n",
      "         [[ 1.6875e-02,  3.0415e-02,  2.9788e-02,  1.9340e-02, -6.5901e-05],\n",
      "          [ 7.6282e-03,  2.2317e-02,  2.8460e-02,  1.6906e-02,  3.6329e-03],\n",
      "          [-1.2207e-03,  1.0802e-02,  9.1866e-03, -1.2800e-03, -8.9357e-03],\n",
      "          [-1.4818e-03,  1.2791e-02,  1.0599e-02, -1.0063e-03, -1.0926e-02],\n",
      "          [ 2.6400e-04,  1.3009e-02,  1.0860e-02, -9.9412e-03, -1.5263e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9479e-02,  2.8747e-02,  2.0076e-02,  9.9554e-03, -4.4400e-03],\n",
      "          [ 2.4499e-02,  2.8746e-02,  2.5028e-02,  1.0687e-02, -6.8576e-03],\n",
      "          [ 1.8666e-02,  2.3925e-02,  1.7253e-02,  3.8245e-03, -3.8907e-03],\n",
      "          [ 9.2807e-03,  1.4406e-02,  6.8667e-03, -3.9407e-03, -9.2668e-03],\n",
      "          [ 3.7596e-03,  8.2153e-03,  3.7176e-03, -4.8212e-03, -9.2610e-03]],\n",
      "\n",
      "         [[ 2.9220e-02,  2.8388e-02,  1.9768e-02,  7.4511e-03, -6.2441e-03],\n",
      "          [ 2.4612e-02,  2.8214e-02,  2.3500e-02,  1.0329e-02, -6.6985e-03],\n",
      "          [ 2.0020e-02,  2.3931e-02,  1.6335e-02,  6.2207e-03, -2.3112e-03],\n",
      "          [ 8.3153e-03,  1.0668e-02,  3.3430e-03, -2.8391e-03, -8.8698e-03],\n",
      "          [ 1.2270e-03,  1.2173e-03, -2.8089e-03, -6.2592e-03, -9.0064e-03]],\n",
      "\n",
      "         [[ 3.3537e-02,  3.3935e-02,  2.5921e-02,  1.2497e-02, -5.5167e-04],\n",
      "          [ 3.2620e-02,  3.5384e-02,  2.9742e-02,  1.7062e-02, -2.9606e-04],\n",
      "          [ 2.9352e-02,  2.9690e-02,  2.2693e-02,  1.5493e-02,  4.7021e-03],\n",
      "          [ 1.9573e-02,  1.6395e-02,  1.1110e-02,  7.8331e-03,  1.8178e-03],\n",
      "          [ 1.2391e-02,  7.1311e-03,  6.3864e-03,  4.5899e-03,  2.4524e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4598e-03, -4.5173e-03, -1.4619e-02, -2.1783e-02, -1.4283e-02],\n",
      "          [ 1.5556e-02,  7.4839e-03, -7.7268e-03, -1.3345e-02, -1.3601e-02],\n",
      "          [ 2.5837e-02,  9.9796e-03,  8.2268e-03, -2.1353e-03, -1.2666e-02],\n",
      "          [ 2.7592e-02,  8.8214e-03,  1.8390e-02,  3.2080e-03, -1.5811e-02],\n",
      "          [ 3.3747e-02,  1.9589e-02,  2.3717e-02,  9.2777e-03, -1.5299e-02]],\n",
      "\n",
      "         [[-1.4208e-02, -1.6486e-02, -2.4162e-02, -2.9680e-02, -2.1619e-02],\n",
      "          [-6.2383e-03, -7.5258e-03, -1.9525e-02, -2.0776e-02, -1.8825e-02],\n",
      "          [ 1.7091e-03, -7.1720e-03, -5.4483e-03, -1.1729e-02, -1.7607e-02],\n",
      "          [ 4.7398e-03, -9.9163e-03,  1.2353e-03, -9.2480e-03, -2.2347e-02],\n",
      "          [ 1.2400e-02,  1.5745e-04,  4.4959e-03, -2.4561e-03, -2.1300e-02]],\n",
      "\n",
      "         [[-8.4506e-04, -1.9117e-03, -1.1881e-02, -1.5336e-02, -5.9232e-03],\n",
      "          [ 2.6186e-03,  6.5408e-03, -9.2243e-03, -8.6877e-03, -2.1567e-03],\n",
      "          [ 2.9580e-03,  4.6229e-03,  4.1911e-03, -2.2318e-03, -1.0253e-04],\n",
      "          [ 4.6318e-03, -2.5417e-03,  7.2131e-03, -1.2407e-03, -7.2342e-03],\n",
      "          [ 1.0750e-02,  2.1533e-03,  4.9257e-03,  5.4679e-03, -4.4047e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1547e-02,  2.0327e-02,  2.0324e-02,  2.3814e-02,  2.6764e-02],\n",
      "          [ 1.3642e-02,  1.9476e-02,  1.2014e-02,  2.2550e-02,  3.4052e-02],\n",
      "          [ 2.1640e-02,  2.3280e-02,  8.9507e-03,  2.1412e-02,  3.3203e-02],\n",
      "          [ 1.4870e-02,  1.5867e-02,  1.1624e-02,  2.0458e-02,  3.0712e-02],\n",
      "          [ 1.2871e-02,  1.8632e-02,  2.1469e-02,  2.0930e-02,  2.8004e-02]],\n",
      "\n",
      "         [[ 1.1368e-02,  2.0222e-02,  1.9035e-02,  1.4713e-02,  1.8589e-02],\n",
      "          [ 1.4956e-02,  2.2350e-02,  1.4328e-02,  1.5506e-02,  2.6516e-02],\n",
      "          [ 2.2582e-02,  2.7237e-02,  1.3070e-02,  1.6871e-02,  2.5769e-02],\n",
      "          [ 1.5588e-02,  2.0314e-02,  1.5133e-02,  1.6103e-02,  2.3381e-02],\n",
      "          [ 1.3092e-02,  2.0862e-02,  2.2340e-02,  1.6694e-02,  2.1188e-02]],\n",
      "\n",
      "         [[ 1.9917e-02,  2.7938e-02,  2.4597e-02,  1.8797e-02,  2.0436e-02],\n",
      "          [ 2.3352e-02,  2.9276e-02,  2.0553e-02,  1.8642e-02,  2.8620e-02],\n",
      "          [ 2.8930e-02,  3.2719e-02,  1.9328e-02,  1.8910e-02,  2.8936e-02],\n",
      "          [ 2.1328e-02,  2.5880e-02,  2.3357e-02,  1.9633e-02,  2.4153e-02],\n",
      "          [ 1.9850e-02,  2.6798e-02,  3.0063e-02,  1.9838e-02,  1.9696e-02]]]])\n",
      "tensor([-0.0056, -0.0737, -0.0201, -0.0579, -0.0316, -0.0298])\n",
      "tensor([[[[-1.4934e-02, -1.6046e-02, -1.9915e-02, -1.9102e-02, -1.8351e-02],\n",
      "          [-8.3708e-03, -1.6413e-03,  3.9588e-04, -6.7538e-03, -3.3502e-03],\n",
      "          [-1.4432e-02, -5.7856e-03, -1.5333e-03,  1.9589e-03,  6.0126e-03],\n",
      "          [-1.7437e-02, -2.9918e-03, -2.0868e-03, -4.6074e-03, -3.0041e-03],\n",
      "          [-1.9215e-02, -5.6295e-03, -6.4253e-03, -1.4470e-02, -1.0910e-02]],\n",
      "\n",
      "         [[-3.1664e-02, -3.2712e-02, -1.7776e-02, -1.6038e-02, -1.4576e-02],\n",
      "          [-3.0206e-02, -4.2024e-02, -2.8915e-02, -2.9417e-02, -2.0348e-02],\n",
      "          [-2.9198e-02, -2.5049e-02, -1.3074e-02, -1.8132e-02, -1.4242e-02],\n",
      "          [-2.7833e-02, -1.5369e-02, -2.4272e-03, -5.6485e-04, -6.4171e-03],\n",
      "          [-2.8463e-02, -1.0671e-02, -3.3725e-03, -3.3597e-03, -1.7290e-04]],\n",
      "\n",
      "         [[-1.3547e-02, -8.8686e-03, -7.9657e-03, -9.5833e-03, -5.7353e-03],\n",
      "          [-1.4809e-02, -1.2974e-02, -1.0616e-02, -7.6184e-03, -3.7558e-03],\n",
      "          [-2.7534e-02, -2.5875e-02, -2.3496e-02, -1.9433e-02, -8.6490e-03],\n",
      "          [-2.8065e-02, -2.1860e-02, -2.6604e-02, -3.2036e-02, -2.5100e-02],\n",
      "          [-3.6086e-02, -3.2909e-02, -2.9665e-02, -1.9546e-02, -1.1394e-02]],\n",
      "\n",
      "         [[-3.0378e-03, -1.6353e-03, -2.7636e-03, -5.1335e-04, -2.9866e-03],\n",
      "          [-4.0130e-03, -5.4249e-03, -8.2946e-03, -2.4656e-03, -1.5715e-03],\n",
      "          [-6.2916e-03, -1.1771e-02, -1.5921e-02, -9.5086e-03, -9.0287e-03],\n",
      "          [-8.8349e-03, -8.8338e-03, -5.7540e-03, -2.4786e-03, -6.5145e-03],\n",
      "          [-3.5167e-03, -3.5300e-03,  3.9816e-03,  4.8864e-03,  2.1137e-03]],\n",
      "\n",
      "         [[-1.1478e-02, -1.3109e-02, -2.9650e-02, -2.9074e-02, -2.0363e-02],\n",
      "          [-1.4652e-02, -1.8721e-03, -2.2451e-02, -3.3270e-02, -1.9281e-02],\n",
      "          [-1.4677e-02, -8.7854e-03, -2.4361e-02, -2.4522e-02, -1.3492e-02],\n",
      "          [-8.8346e-03, -1.5853e-02, -2.5948e-02, -1.9929e-02, -1.1159e-02],\n",
      "          [-1.1294e-02, -2.9368e-02, -3.2917e-02, -1.8133e-02, -1.1315e-02]],\n",
      "\n",
      "         [[-4.2914e-03, -3.0169e-03, -8.8051e-03, -5.0729e-03, -9.4739e-03],\n",
      "          [-1.6588e-02, -9.7137e-03, -1.3086e-02, -1.2958e-02, -1.6819e-02],\n",
      "          [-2.3975e-02, -1.7085e-02, -1.7170e-02, -8.9699e-03, -9.7983e-03],\n",
      "          [-1.2838e-02, -1.8021e-02, -2.2354e-02, -8.6856e-03, -9.5147e-03],\n",
      "          [-1.1220e-02, -1.0466e-02, -1.4342e-02,  2.4785e-03, -8.5810e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.2501e-03, -7.9280e-03, -4.5855e-03, -3.3472e-03, -4.3220e-03],\n",
      "          [-1.3808e-03, -4.7239e-03, -8.0342e-04, -2.6028e-03, -3.5120e-03],\n",
      "          [-2.4564e-03, -8.2821e-03, -5.5059e-03, -9.7469e-03, -5.8760e-03],\n",
      "          [-1.9689e-03, -2.0345e-03, -4.5588e-04, -6.7760e-03, -3.4833e-03],\n",
      "          [-3.9576e-03, -2.6897e-03, -2.4965e-03, -5.7839e-03, -2.4536e-03]],\n",
      "\n",
      "         [[-1.7580e-03, -3.5743e-03, -5.0892e-03,  2.4410e-03, -2.0582e-03],\n",
      "          [-1.0982e-03,  2.3776e-03,  1.6659e-03,  7.3562e-03, -2.8723e-04],\n",
      "          [-5.8358e-04, -3.8471e-03,  1.3728e-04, -8.3678e-04, -6.4071e-03],\n",
      "          [-4.2822e-04, -4.1999e-03,  6.5451e-04, -6.0225e-03, -9.8238e-03],\n",
      "          [ 6.6202e-04,  2.6452e-03,  8.0177e-03,  3.0027e-03,  5.2974e-05]],\n",
      "\n",
      "         [[ 1.5485e-03,  3.5694e-04,  2.3017e-03, -2.9159e-03, -4.5531e-03],\n",
      "          [ 1.3572e-03, -2.2102e-03, -1.7873e-03, -4.4224e-03, -5.6540e-03],\n",
      "          [-7.3690e-03, -8.4126e-03, -6.4513e-03, -5.6915e-03, -5.5937e-03],\n",
      "          [-5.3445e-04,  7.8821e-04,  1.6321e-03,  2.3226e-03,  1.0811e-03],\n",
      "          [-3.7744e-03, -3.4296e-03, -5.8851e-03, -9.6632e-03, -1.2919e-02]],\n",
      "\n",
      "         [[ 1.7149e-03,  1.0815e-03,  1.7304e-03, -5.6910e-04, -1.7940e-03],\n",
      "          [-7.7790e-05, -1.3455e-03, -2.2277e-03,  4.6581e-04,  6.2564e-04],\n",
      "          [ 1.4985e-05,  1.2975e-03,  6.1476e-04,  2.6366e-03,  3.0353e-03],\n",
      "          [ 3.8759e-04,  9.9588e-04, -6.8891e-05, -2.7167e-04, -1.6309e-03],\n",
      "          [-1.3595e-03, -1.8317e-04, -3.0315e-03, -1.6930e-03, -5.3297e-03]],\n",
      "\n",
      "         [[-4.5559e-03, -3.0749e-03, -3.7955e-03, -6.7295e-03, -5.3179e-03],\n",
      "          [-7.6776e-03, -4.1754e-03, -2.8698e-03, -5.4950e-03, -4.5074e-03],\n",
      "          [-6.4123e-03, -4.6065e-03, -3.5989e-03, -5.8120e-03, -5.5188e-03],\n",
      "          [-5.7134e-03, -4.4942e-03, -1.8760e-03,  1.1914e-03, -2.6671e-03],\n",
      "          [-5.0744e-03, -6.1670e-03, -5.5456e-03,  8.1681e-04, -2.2935e-05]],\n",
      "\n",
      "         [[ 1.8551e-03, -1.3975e-03,  1.0750e-04, -3.1980e-03, -8.5899e-04],\n",
      "          [-1.2805e-03, -2.6951e-03,  2.2752e-03, -3.0286e-03,  4.4766e-03],\n",
      "          [-2.8301e-03, -1.3718e-03,  2.1354e-03, -1.2939e-03, -9.1870e-04],\n",
      "          [-4.0031e-03, -3.2949e-03,  6.0000e-04, -2.0963e-03,  2.6152e-03],\n",
      "          [-2.3683e-03, -4.5388e-03, -1.0289e-03, -2.7639e-03,  3.3114e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9250e-03, -2.2974e-03,  1.6244e-03,  3.5237e-03,  2.3713e-04],\n",
      "          [-1.1306e-03, -2.4778e-03,  9.8899e-05,  1.6350e-03,  2.4884e-03],\n",
      "          [-8.5984e-03, -2.9806e-03,  9.3851e-04,  6.4790e-03, -2.7350e-03],\n",
      "          [-7.5295e-03, -1.8638e-03,  1.5055e-03,  7.1413e-04, -4.4910e-03],\n",
      "          [-2.6284e-03, -1.0002e-04,  2.4051e-03, -1.2193e-03, -2.7870e-03]],\n",
      "\n",
      "         [[-1.1912e-02, -1.2131e-02, -1.1168e-02, -5.8613e-03,  5.5265e-03],\n",
      "          [-1.5011e-02, -1.8870e-02, -1.7602e-02, -7.1434e-03,  1.6879e-03],\n",
      "          [-1.9607e-02, -2.1510e-02, -1.5249e-02, -8.8581e-04,  6.5084e-03],\n",
      "          [-1.9888e-02, -2.1850e-02, -4.1289e-03,  5.4476e-03,  1.5924e-02],\n",
      "          [-1.0305e-02, -9.3670e-03,  1.9043e-03,  8.4600e-03,  1.1605e-02]],\n",
      "\n",
      "         [[-4.9515e-03, -3.7488e-04, -8.1885e-03, -6.7584e-03, -7.4348e-03],\n",
      "          [-7.0356e-03,  4.2422e-03,  4.9392e-03,  3.1692e-03, -1.1713e-03],\n",
      "          [-6.4230e-03, -1.5977e-03, -2.6593e-03,  4.3255e-04, -1.4862e-03],\n",
      "          [-8.1564e-03, -9.4962e-03, -1.2147e-02, -1.3799e-02, -1.5258e-02],\n",
      "          [-2.0961e-02, -2.4588e-02, -1.6828e-02, -3.8649e-03, -3.9180e-03]],\n",
      "\n",
      "         [[-3.7364e-03,  2.0354e-03, -2.4122e-04, -3.2161e-03, -6.2532e-03],\n",
      "          [-8.2419e-03, -4.6309e-03, -2.9168e-03, -3.8610e-03, -7.5340e-03],\n",
      "          [-9.0673e-03, -9.1403e-03, -9.9418e-03, -6.4674e-03, -2.6424e-03],\n",
      "          [-1.1766e-02, -1.2113e-02, -1.2415e-02, -7.3770e-03, -6.6569e-03],\n",
      "          [-9.9586e-03, -1.1440e-02, -1.1676e-02, -5.5694e-03, -1.4407e-03]],\n",
      "\n",
      "         [[ 9.6263e-03,  6.1683e-03, -2.1389e-03, -7.9268e-03, -1.1892e-02],\n",
      "          [ 1.0614e-02,  5.7405e-03, -4.7849e-03, -8.3943e-03, -9.6007e-03],\n",
      "          [ 1.6738e-03,  1.9472e-03, -8.1896e-03, -1.9423e-02, -1.2041e-02],\n",
      "          [ 8.7114e-03,  2.4665e-04, -6.5936e-03, -1.6871e-02, -1.4545e-02],\n",
      "          [ 1.2148e-02, -1.1922e-03, -2.9917e-03, -5.8813e-03, -5.9580e-03]],\n",
      "\n",
      "         [[-7.8392e-03, -3.4316e-03, -7.2272e-03, -6.5065e-03, -2.2192e-03],\n",
      "          [-5.8396e-03, -1.6537e-03, -6.0986e-03, -1.1936e-02, -8.0177e-03],\n",
      "          [-7.4898e-03, -1.0351e-02, -9.7003e-03, -1.2497e-02, -6.8501e-03],\n",
      "          [-2.4526e-03, -1.2634e-02, -1.2728e-02, -1.0172e-02, -1.0320e-02],\n",
      "          [-2.2447e-03, -6.3709e-03, -5.1290e-03, -7.4144e-04,  4.5446e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.7020e-03, -3.2312e-03, -2.6797e-03, -3.4741e-03, -3.1109e-03],\n",
      "          [-3.2471e-03, -5.0743e-03, -4.8805e-03, -4.9465e-03, -3.1145e-03],\n",
      "          [-2.5510e-04, -2.3417e-03, -3.8577e-03, -4.6659e-03, -4.4405e-03],\n",
      "          [-1.7275e-03, -3.0590e-03, -3.5762e-03, -6.2087e-03, -5.1420e-03],\n",
      "          [-8.6631e-04, -2.1187e-03, -1.3402e-04, -2.4714e-03, -2.7461e-03]],\n",
      "\n",
      "         [[ 6.7315e-04,  8.1721e-05,  8.2551e-04, -2.0590e-03, -6.3360e-03],\n",
      "          [ 1.3133e-03,  1.3902e-03,  1.5858e-03, -7.8383e-04, -3.9817e-03],\n",
      "          [ 1.9050e-03,  2.2044e-03,  1.6370e-03, -1.1068e-03, -2.5889e-03],\n",
      "          [-4.7815e-04, -8.4307e-04,  8.1118e-04, -2.5070e-03, -5.3702e-03],\n",
      "          [ 2.0057e-04, -1.3483e-03,  5.0457e-04, -1.6709e-03, -5.9896e-03]],\n",
      "\n",
      "         [[-1.4279e-03, -2.2427e-04, -3.8883e-04,  8.0806e-04,  4.7273e-04],\n",
      "          [-3.1360e-03, -1.4429e-03, -1.5870e-03, -5.6288e-04, -1.2349e-03],\n",
      "          [-7.2593e-04, -1.2833e-04, -6.3083e-04,  1.4676e-04, -1.3477e-03],\n",
      "          [-6.2665e-03, -3.9928e-03, -3.4224e-03, -2.6459e-03, -2.5182e-03],\n",
      "          [-1.6202e-03, -1.0480e-03, -4.7671e-05,  3.3237e-04, -1.5592e-04]],\n",
      "\n",
      "         [[ 7.3480e-05,  4.1614e-04, -7.7941e-05,  0.0000e+00, -6.2278e-04],\n",
      "          [-6.3980e-04, -3.9265e-05,  0.0000e+00,  5.2494e-06, -8.4104e-04],\n",
      "          [-1.0156e-04,  9.3740e-05,  1.8882e-04,  2.7643e-04, -1.5425e-04],\n",
      "          [ 6.9906e-05,  3.7699e-04,  4.3582e-04,  5.4323e-04,  3.9035e-04],\n",
      "          [ 7.7388e-04, -9.8488e-04, -1.3333e-03,  1.0970e-03, -6.5914e-04]],\n",
      "\n",
      "         [[-2.5771e-03, -1.0945e-03, -1.4699e-03, -3.7226e-04, -3.4223e-04],\n",
      "          [-6.0011e-03, -3.2727e-03, -2.7888e-03, -7.8912e-04, -3.8579e-04],\n",
      "          [-4.4660e-03, -3.7583e-03, -1.7600e-03, -1.9008e-03, -1.0298e-03],\n",
      "          [-4.2548e-03, -6.3582e-03, -3.9773e-03, -3.2039e-03, -1.4713e-03],\n",
      "          [-3.6278e-03, -4.2187e-03, -2.0946e-03,  9.1816e-05,  6.3877e-04]],\n",
      "\n",
      "         [[-2.5700e-03,  1.3992e-03, -1.5555e-05,  1.4279e-04, -1.0860e-03],\n",
      "          [-1.2881e-03,  1.6571e-03,  4.8811e-04,  5.8662e-04, -2.2762e-03],\n",
      "          [-1.5001e-03,  1.4398e-03,  1.8055e-03,  1.3110e-03, -2.3797e-03],\n",
      "          [-1.1377e-03,  6.5042e-04,  1.5127e-03,  7.8737e-04, -1.5916e-03],\n",
      "          [-3.0871e-03,  9.2823e-04,  7.6488e-04,  1.1696e-03,  3.4837e-05]]],\n",
      "\n",
      "\n",
      "        [[[-4.7556e-03,  7.8752e-05, -3.6371e-03, -8.2377e-03, -1.8975e-02],\n",
      "          [-2.7215e-03,  1.0289e-03, -3.2007e-03, -8.3257e-03, -1.2518e-02],\n",
      "          [-1.5434e-03,  5.7667e-04, -7.8733e-03, -8.7609e-03, -1.0280e-02],\n",
      "          [-1.7218e-03, -3.0635e-03, -1.2585e-02, -1.5844e-02, -1.3041e-02],\n",
      "          [-1.5252e-04, -1.8293e-03, -8.2667e-03, -1.1834e-02, -8.1896e-03]],\n",
      "\n",
      "         [[-2.0682e-02, -1.9185e-02, -1.2173e-02, -1.1674e-02, -1.6068e-02],\n",
      "          [-2.0431e-02, -1.4600e-02, -1.3168e-02, -1.7049e-02, -1.3918e-02],\n",
      "          [-1.2263e-02, -1.8900e-03, -4.4606e-03, -1.1578e-02, -1.1314e-02],\n",
      "          [-1.1028e-02,  9.5278e-04, -2.1921e-03, -1.3639e-02, -1.8396e-02],\n",
      "          [-5.0412e-03,  6.7028e-04, -3.1804e-03, -1.7237e-02, -2.1040e-02]],\n",
      "\n",
      "         [[-1.1795e-02, -1.3021e-02, -1.1670e-02, -1.2894e-02, -8.9872e-03],\n",
      "          [-1.3882e-02, -1.2681e-02, -1.4465e-02, -1.3352e-02, -4.9952e-03],\n",
      "          [-1.0326e-02, -1.5185e-02, -1.5727e-02, -1.3217e-02, -1.7936e-02],\n",
      "          [-1.3676e-02, -1.6232e-02, -1.8056e-02, -1.7236e-02, -2.2768e-02],\n",
      "          [-1.2643e-02, -5.4731e-03, -3.2591e-03, -3.7290e-03, -1.0198e-02]],\n",
      "\n",
      "         [[-4.3695e-04, -7.1847e-03, -7.5026e-03, -5.8086e-03, -1.0892e-03],\n",
      "          [-2.1516e-03, -8.0594e-03, -5.5905e-03, -4.2367e-03, -3.6822e-03],\n",
      "          [-6.5041e-03, -1.0010e-02, -5.0894e-03, -6.1818e-03, -3.1456e-03],\n",
      "          [-6.8096e-03, -5.3168e-03, -4.5976e-04, -1.2020e-03, -4.1229e-03],\n",
      "          [-3.0373e-03, -2.9756e-03,  2.5265e-03,  7.3931e-04, -5.7760e-03]],\n",
      "\n",
      "         [[ 1.2597e-03, -8.5474e-03, -1.6344e-02, -1.2339e-02, -6.6452e-03],\n",
      "          [-1.8307e-03, -1.2351e-02, -1.3811e-02, -6.5341e-03, -7.0167e-03],\n",
      "          [-5.8101e-03, -2.0191e-02, -1.1904e-02, -1.9353e-03, -6.3168e-03],\n",
      "          [-7.1381e-03, -1.7625e-02, -5.1778e-03,  1.5306e-03, -2.2677e-03],\n",
      "          [-1.2102e-02, -1.3980e-02, -2.2261e-03,  1.3542e-05, -4.0488e-03]],\n",
      "\n",
      "         [[-1.1805e-02, -1.3584e-02, -1.9994e-02, -5.2701e-03, -1.7130e-03],\n",
      "          [-1.3258e-02, -1.6457e-02, -2.0896e-02, -5.2432e-03, -5.0374e-03],\n",
      "          [-8.6894e-03, -1.3383e-02, -1.1109e-02, -6.5814e-03, -7.4543e-03],\n",
      "          [-7.7927e-03, -1.2042e-02, -8.7675e-03, -4.4626e-03, -5.8627e-03],\n",
      "          [-5.0031e-03, -8.3020e-03, -3.3284e-03, -4.7930e-03, -9.4027e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.6075e-03, -5.9448e-03, -8.2340e-03, -4.3049e-03, -1.7430e-03],\n",
      "          [-2.5753e-03, -6.5916e-03, -6.0145e-03, -6.8465e-03, -1.1821e-04],\n",
      "          [-2.1571e-03, -5.6238e-03, -4.7785e-03, -7.4756e-03, -4.3699e-03],\n",
      "          [-2.6620e-04, -3.0774e-03,  6.6694e-04,  2.8789e-03,  3.6275e-04],\n",
      "          [ 1.4649e-04, -2.8834e-03, -1.4407e-03, -5.6129e-04,  1.5740e-03]],\n",
      "\n",
      "         [[ 8.6763e-03,  6.2293e-03,  2.8010e-03, -5.4077e-05, -2.4259e-03],\n",
      "          [ 1.9885e-03,  1.6215e-03, -2.6019e-03, -2.2039e-03, -3.2806e-05],\n",
      "          [ 1.5198e-03, -4.9796e-03, -7.9250e-03, -4.2885e-03,  3.7657e-03],\n",
      "          [-4.4197e-03, -8.9036e-03, -1.0208e-02, -3.1043e-03, -4.7820e-03],\n",
      "          [-1.7833e-03, -7.6750e-03, -1.1174e-02, -3.8612e-03, -6.2724e-03]],\n",
      "\n",
      "         [[-2.4625e-03, -5.1086e-04,  5.0990e-03,  4.0711e-03,  2.4243e-03],\n",
      "          [ 2.7725e-03,  4.6111e-03,  3.8319e-03,  4.4129e-03,  4.6964e-03],\n",
      "          [ 2.4762e-03,  3.9832e-03,  1.8655e-03,  5.3509e-04,  4.7655e-03],\n",
      "          [ 1.4470e-03,  5.0114e-04, -1.8892e-03,  7.9229e-04,  1.1197e-02],\n",
      "          [-1.8427e-03,  1.9349e-03, -5.1057e-03, -4.6728e-03,  4.7152e-04]],\n",
      "\n",
      "         [[-3.8400e-04,  3.1845e-04,  6.3394e-04,  1.0481e-03, -1.3826e-03],\n",
      "          [-5.0322e-04,  1.7953e-03,  1.3832e-04,  1.1122e-03,  2.0134e-03],\n",
      "          [ 7.1648e-04,  7.6483e-04, -1.3192e-03,  4.3197e-04,  6.0387e-04],\n",
      "          [-8.4628e-05,  9.1380e-04, -4.0824e-03, -5.1765e-03, -2.2704e-03],\n",
      "          [-4.5404e-03, -5.1044e-03, -5.7548e-03, -4.5079e-03, -6.6898e-03]],\n",
      "\n",
      "         [[-1.6894e-03, -6.3647e-04,  3.4092e-03,  6.2432e-03,  2.8225e-03],\n",
      "          [-8.3428e-04, -2.0325e-04,  3.7622e-04, -5.2864e-04,  3.8282e-03],\n",
      "          [-3.2094e-03,  3.0189e-03,  4.5349e-05, -3.5608e-03, -1.0919e-03],\n",
      "          [ 1.1773e-04,  2.1405e-03, -2.0277e-03, -5.7629e-03,  1.2691e-03],\n",
      "          [ 5.0243e-03,  2.3755e-03, -3.8650e-03, -7.3241e-03,  1.4127e-03]],\n",
      "\n",
      "         [[ 2.5355e-03,  5.7878e-03,  4.1267e-03,  1.8433e-03,  1.1319e-03],\n",
      "          [ 2.3181e-03,  3.6256e-03,  5.4343e-03,  4.8775e-03, -1.6819e-03],\n",
      "          [-1.0654e-03,  3.6346e-03,  1.3140e-03,  1.3297e-04, -3.4155e-03],\n",
      "          [-5.3535e-03, -3.0646e-03, -4.6926e-03, -1.6360e-03, -3.1206e-03],\n",
      "          [-5.2891e-03, -2.4383e-03, -7.3964e-03, -9.3680e-03, -4.7723e-03]]]])\n",
      "tensor([-0.0693, -0.0272, -0.0048, -0.0825, -0.0526, -0.0529, -0.0380, -0.0166,\n",
      "        -0.0401, -0.0301, -0.0009, -0.0452, -0.0297, -0.0161, -0.0442, -0.0055])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0013,  0.0024,  0.0022,  ...,  0.0005,  0.0006,  0.0000],\n",
      "        [ 0.0023,  0.0003,  0.0011,  ..., -0.0009, -0.0013,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0002, -0.0021,  ..., -0.0006, -0.0008,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0020, -0.0022, -0.0035,  ..., -0.0002, -0.0003,  0.0000]])\n",
      "tensor([ 0.0000,  0.0419, -0.0354,  0.0194,  0.0000,  0.0000,  0.0055, -0.0375,\n",
      "         0.0045, -0.0066,  0.0000, -0.0012, -0.0525, -0.0364,  0.0039, -0.0269,\n",
      "        -0.0083, -0.0141, -0.0141, -0.0210, -0.0095,  0.0027, -0.0016,  0.0015,\n",
      "         0.0000, -0.0162,  0.0000, -0.0325, -0.0679,  0.0000,  0.0007,  0.0000,\n",
      "         0.0000,  0.0000, -0.0135,  0.0099,  0.0102,  0.0019, -0.0408, -0.0189,\n",
      "        -0.0341,  0.0000, -0.0164,  0.0000, -0.0341,  0.0000,  0.0048,  0.0000,\n",
      "         0.0000,  0.0314,  0.0000, -0.0678,  0.0000,  0.0315,  0.0003,  0.0008,\n",
      "         0.0051, -0.0689, -0.0102,  0.0071,  0.0071, -0.0474,  0.0006,  0.0114,\n",
      "         0.0000,  0.0128, -0.0177,  0.0349, -0.0185,  0.0000, -0.0473,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0322, -0.0285, -0.0242,  0.0000, -0.0555,\n",
      "         0.0000,  0.0000,  0.0158, -0.0078,  0.0000, -0.0249,  0.0067, -0.0127,\n",
      "         0.0100, -0.0326,  0.0000,  0.0000,  0.0000, -0.0335, -0.0045,  0.0000,\n",
      "         0.0084,  0.0022,  0.0314,  0.0033,  0.0093,  0.0046,  0.0000,  0.0009,\n",
      "         0.0000,  0.0008, -0.0309, -0.0027, -0.0123, -0.0202,  0.0035,  0.0109,\n",
      "         0.0000,  0.0000,  0.0298, -0.0139,  0.0000, -0.0221,  0.0000, -0.0237])\n",
      "tensor([[ 0.0000,  0.0061,  0.0174,  ...,  0.0220,  0.0000,  0.0229],\n",
      "        [ 0.0000,  0.0030, -0.0080,  ...,  0.0003,  0.0000,  0.0042],\n",
      "        [ 0.0000, -0.0017,  0.0033,  ..., -0.0030,  0.0000,  0.0009],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0027,  0.0058,  ...,  0.0152,  0.0000, -0.0026],\n",
      "        [ 0.0000, -0.0014, -0.0175,  ...,  0.0052,  0.0000, -0.0134],\n",
      "        [ 0.0000, -0.0069, -0.0477,  ..., -0.0308,  0.0000, -0.0365]])\n",
      "tensor([ 0.1139, -0.0152, -0.0007, -0.0464, -0.2341, -0.1128, -0.0775,  0.0372,\n",
      "         0.0000,  0.0098, -0.1011, -0.0430, -0.0519,  0.0342, -0.0713,  0.0000,\n",
      "        -0.0382, -0.0583, -0.0133,  0.0000,  0.1928,  0.0551, -0.1103,  0.0016,\n",
      "         0.0206, -0.0167, -0.0065, -0.1839, -0.2673,  0.0000,  0.0000, -0.0458,\n",
      "         0.1255,  0.0000,  0.0184,  0.0000, -0.0818,  0.0157,  0.0812, -0.0214,\n",
      "        -0.0008,  0.0233, -0.0601,  0.0000, -0.0790,  0.0000, -0.0263,  0.0000,\n",
      "         0.0000,  0.0027,  0.0260,  0.0000, -0.1028, -0.2033, -0.0449,  0.0000,\n",
      "        -0.1316,  0.0686,  0.0142,  0.0000,  0.0301, -0.1746,  0.0000,  0.0000,\n",
      "        -0.0694,  0.0034,  0.0084,  0.1156,  0.1375, -0.0368,  0.0000,  0.0095,\n",
      "        -0.0013, -0.0553,  0.0000,  0.0000, -0.0228, -0.0029, -0.0746, -0.0157,\n",
      "        -0.1654,  0.0393, -0.0242, -0.2363])\n",
      "tensor([[ 6.6343e-02,  3.1182e-02,  2.1449e-03,  6.3522e-03,  5.4147e-02,\n",
      "          1.3588e-02,  1.1164e-02,  1.6349e-03,  0.0000e+00,  9.7844e-05,\n",
      "          1.8141e-02,  1.6206e-02,  2.5256e-02,  1.9499e-03,  7.4551e-04,\n",
      "          0.0000e+00,  5.8560e-02,  4.4986e-02,  1.8756e-02,  0.0000e+00,\n",
      "          3.5090e-02,  1.3197e-02,  1.0391e-02,  4.9364e-03,  1.1651e-02,\n",
      "          1.5809e-02,  1.0548e-04,  1.9682e-02,  3.5398e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.1905e-02,  1.5512e-02,  0.0000e+00,  6.8537e-04,\n",
      "          0.0000e+00,  3.5368e-02,  1.8529e-03,  7.0305e-04,  1.2680e-02,\n",
      "          3.0698e-03,  1.0770e-03,  3.3572e-02,  0.0000e+00,  2.3585e-03,\n",
      "          0.0000e+00,  3.2051e-02,  0.0000e+00,  0.0000e+00,  5.3427e-05,\n",
      "          5.5999e-04,  0.0000e+00,  1.0886e-02,  4.7379e-02,  8.8714e-03,\n",
      "          0.0000e+00,  2.5534e-02,  1.4567e-03,  1.7786e-03,  0.0000e+00,\n",
      "          4.6403e-04,  2.9837e-02,  0.0000e+00,  0.0000e+00,  6.7249e-03,\n",
      "          2.4613e-03,  7.8048e-02,  4.1719e-02,  1.1380e-02,  2.1018e-02,\n",
      "          0.0000e+00,  6.0210e-03,  1.4744e-02,  5.0425e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.6654e-02,  5.4256e-02,  7.3338e-03,  7.3882e-03,\n",
      "          1.4869e-02,  6.6720e-02,  9.3572e-03,  4.4767e-02],\n",
      "        [-1.1920e-01, -2.9276e-02,  2.2033e-03, -3.2089e-02, -7.2251e-02,\n",
      "         -1.1694e-02, -1.3125e-02, -9.0313e-03,  0.0000e+00,  9.9332e-05,\n",
      "         -8.2413e-03, -5.9610e-02, -5.3808e-02,  2.0376e-03, -7.3432e-03,\n",
      "          0.0000e+00, -4.0294e-02, -1.7313e-02, -4.4972e-02,  0.0000e+00,\n",
      "         -5.5821e-02, -2.5798e-02, -1.1314e-02,  3.0337e-03, -1.5101e-02,\n",
      "         -4.7765e-02,  1.0936e-04, -1.9012e-02, -7.8581e-02,  0.0000e+00,\n",
      "          0.0000e+00, -6.3096e-02, -4.7739e-02,  0.0000e+00,  1.7149e-05,\n",
      "          0.0000e+00, -5.6131e-02, -4.9952e-03,  7.0346e-04, -1.0262e-02,\n",
      "         -2.5652e-02,  1.1392e-03, -3.6894e-02,  0.0000e+00, -8.5832e-03,\n",
      "          0.0000e+00, -3.4882e-02,  0.0000e+00,  0.0000e+00,  1.9001e-05,\n",
      "         -1.7315e-03,  0.0000e+00, -6.4706e-02, -1.0730e-01, -1.4712e-02,\n",
      "          0.0000e+00,  1.1619e-02,  1.4406e-03,  1.7964e-03,  0.0000e+00,\n",
      "         -8.8332e-04, -5.4779e-02,  0.0000e+00,  0.0000e+00,  4.5493e-03,\n",
      "          2.4338e-03, -7.8783e-02, -5.8274e-02, -1.8703e-02, -3.4139e-02,\n",
      "          0.0000e+00, -1.3836e-02,  2.8328e-03, -3.6032e-02,  0.0000e+00,\n",
      "          0.0000e+00, -2.9140e-02, -5.2841e-02, -4.1113e-02, -1.2616e-02,\n",
      "         -7.4183e-02, -5.9915e-02, -1.2996e-03, -7.2468e-02],\n",
      "        [-6.7920e-02, -9.6851e-02,  2.7716e-03, -6.4374e-03, -7.4511e-02,\n",
      "         -1.3198e-03, -4.7184e-02, -8.7997e-04,  0.0000e+00,  1.2278e-04,\n",
      "         -4.6644e-02,  2.0413e-03, -1.3056e-02,  2.5900e-03,  9.2839e-04,\n",
      "          0.0000e+00, -1.0117e-01, -6.9846e-02, -4.1230e-02,  0.0000e+00,\n",
      "         -5.8579e-02, -2.9231e-02, -3.2939e-02,  5.9846e-03, -1.1835e-02,\n",
      "         -5.8909e-02, -1.0180e-03, -3.3139e-02, -3.3308e-02,  0.0000e+00,\n",
      "          0.0000e+00, -4.7668e-02, -2.4098e-02,  0.0000e+00, -3.4191e-03,\n",
      "          0.0000e+00, -5.2652e-02, -5.8208e-03,  8.6982e-04, -4.9246e-02,\n",
      "         -4.3715e-04,  1.4600e-03, -2.8248e-02,  0.0000e+00, -1.1502e-02,\n",
      "          0.0000e+00, -3.2568e-02,  0.0000e+00,  0.0000e+00, -4.7250e-04,\n",
      "          2.7353e-04,  0.0000e+00, -1.9963e-02, -9.0508e-02, -2.2684e-02,\n",
      "          0.0000e+00, -4.8054e-02,  1.7754e-03,  1.4187e-03,  0.0000e+00,\n",
      "          5.3514e-04,  4.7174e-03,  0.0000e+00,  0.0000e+00, -1.3144e-02,\n",
      "          2.9975e-03, -7.2240e-02, -6.3235e-02, -1.7440e-02, -6.1010e-02,\n",
      "          0.0000e+00, -2.2734e-03,  2.1876e-03,  6.2369e-03,  0.0000e+00,\n",
      "          0.0000e+00, -5.0028e-02, -7.9765e-02, -6.5377e-03, -1.1933e-02,\n",
      "         -2.5384e-02, -8.1433e-02,  3.1965e-03, -6.2759e-02],\n",
      "        [ 6.6271e-02,  3.0947e-02,  2.1404e-03,  6.3145e-03,  5.3846e-02,\n",
      "          1.3608e-02,  1.1002e-02,  1.6152e-03,  0.0000e+00,  1.0131e-04,\n",
      "          1.8032e-02,  1.6176e-02,  2.5368e-02,  1.9795e-03,  7.3710e-04,\n",
      "          0.0000e+00,  5.8447e-02,  4.4998e-02,  1.8680e-02,  0.0000e+00,\n",
      "          3.4977e-02,  1.3216e-02,  1.0264e-02,  5.0118e-03,  1.1627e-02,\n",
      "          1.5551e-02,  9.9857e-05,  1.9544e-02,  3.5361e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.1815e-02,  1.5448e-02,  0.0000e+00,  6.8208e-04,\n",
      "          0.0000e+00,  3.5329e-02,  1.8546e-03,  7.0072e-04,  1.2593e-02,\n",
      "          3.0403e-03,  1.1105e-03,  3.3538e-02,  0.0000e+00,  2.3179e-03,\n",
      "          0.0000e+00,  3.2036e-02,  0.0000e+00,  0.0000e+00,  5.3150e-05,\n",
      "          5.5642e-04,  0.0000e+00,  1.0781e-02,  4.7029e-02,  8.7512e-03,\n",
      "          0.0000e+00,  2.5569e-02,  1.4899e-03,  1.7691e-03,  0.0000e+00,\n",
      "          4.6201e-04,  2.9964e-02,  0.0000e+00,  0.0000e+00,  6.7386e-03,\n",
      "          2.4958e-03,  7.8190e-02,  4.1775e-02,  1.1379e-02,  2.0837e-02,\n",
      "          0.0000e+00,  5.9958e-03,  1.4975e-02,  4.9819e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.6573e-02,  5.4228e-02,  7.2845e-03,  7.3683e-03,\n",
      "          1.4676e-02,  6.6597e-02,  9.3751e-03,  4.4585e-02],\n",
      "        [-9.5719e-02, -2.8368e-02, -1.5345e-02, -7.2727e-03, -1.0953e-01,\n",
      "         -2.9917e-02,  1.0391e-02,  2.0348e-03,  0.0000e+00,  1.1950e-04,\n",
      "         -2.0676e-02, -2.1065e-02,  4.3962e-03, -4.6801e-03,  9.0378e-04,\n",
      "          0.0000e+00, -8.0991e-02, -5.2752e-02, -2.7871e-03,  0.0000e+00,\n",
      "         -6.2724e-02, -1.8959e-03, -2.3024e-03, -1.3849e-02, -3.3338e-02,\n",
      "         -8.9040e-03,  1.2956e-04, -3.7438e-02, -2.0377e-02,  0.0000e+00,\n",
      "          0.0000e+00, -1.0784e-01, -1.6348e-02,  0.0000e+00, -1.6356e-03,\n",
      "          0.0000e+00, -3.2498e-02,  2.1459e-03, -6.8610e-03,  9.0383e-05,\n",
      "          3.5763e-03,  1.3905e-03, -7.0554e-02,  0.0000e+00,  2.7571e-03,\n",
      "          0.0000e+00, -4.5930e-02,  0.0000e+00,  0.0000e+00,  6.0752e-05,\n",
      "         -9.5573e-04,  0.0000e+00,  8.7600e-03, -3.7462e-02, -2.8421e-02,\n",
      "          0.0000e+00, -4.1762e-02,  1.7386e-03, -1.5001e-02,  0.0000e+00,\n",
      "         -3.0669e-03, -3.1198e-02,  0.0000e+00,  0.0000e+00, -2.1445e-03,\n",
      "         -6.5439e-03, -1.2242e-01, -1.6113e-02, -1.7262e-02, -2.2869e-02,\n",
      "          0.0000e+00, -1.2857e-02, -7.5490e-03, -7.5428e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.3230e-02, -9.1353e-02, -1.5155e-03, -1.4721e-02,\n",
      "         -2.1830e-03, -1.5210e-01, -4.7797e-02, -7.4567e-02],\n",
      "        [ 8.2910e-02,  3.8842e-02,  2.7405e-03,  7.7029e-03,  6.7916e-02,\n",
      "          1.7386e-02,  1.3973e-02,  2.0533e-03,  0.0000e+00,  1.2935e-04,\n",
      "          2.2798e-02,  2.0007e-02,  3.1764e-02,  2.5735e-03,  9.1261e-04,\n",
      "          0.0000e+00,  7.3858e-02,  5.6930e-02,  2.3168e-02,  0.0000e+00,\n",
      "          4.3445e-02,  1.6363e-02,  1.3085e-02,  6.3850e-03,  1.4391e-02,\n",
      "          1.9272e-02,  1.2810e-04,  2.4848e-02,  4.4682e-02,  0.0000e+00,\n",
      "          0.0000e+00,  6.5226e-02,  1.8889e-02,  0.0000e+00,  8.2788e-04,\n",
      "          0.0000e+00,  4.4506e-02,  2.2946e-03,  8.8126e-04,  1.5492e-02,\n",
      "          3.7023e-03,  1.4609e-03,  4.2475e-02,  0.0000e+00,  2.8478e-03,\n",
      "          0.0000e+00,  4.0558e-02,  0.0000e+00,  0.0000e+00,  6.4493e-05,\n",
      "          6.7616e-04,  0.0000e+00,  1.3223e-02,  5.8956e-02,  1.0886e-02,\n",
      "          0.0000e+00,  3.2530e-02,  1.8803e-03,  2.2387e-03,  0.0000e+00,\n",
      "          5.6224e-04,  3.8010e-02,  0.0000e+00,  0.0000e+00,  8.6775e-03,\n",
      "          3.1382e-03,  9.8074e-02,  5.2407e-02,  1.3973e-02,  2.6029e-02,\n",
      "          0.0000e+00,  7.3032e-03,  1.9027e-02,  6.1823e-03,  0.0000e+00,\n",
      "          0.0000e+00,  2.0899e-02,  6.7801e-02,  8.8823e-03,  9.0136e-03,\n",
      "          1.8118e-02,  8.3536e-02,  1.1702e-02,  5.6036e-02],\n",
      "        [ 6.6426e-02,  3.1085e-02,  2.1605e-03,  6.3280e-03,  5.3979e-02,\n",
      "          1.3577e-02,  1.0988e-02,  1.5850e-03,  0.0000e+00,  1.0086e-04,\n",
      "          1.8096e-02,  1.6185e-02,  2.5300e-02,  1.9660e-03,  7.1949e-04,\n",
      "          0.0000e+00,  5.8583e-02,  4.5076e-02,  1.8727e-02,  0.0000e+00,\n",
      "          3.5205e-02,  1.3273e-02,  1.0242e-02,  5.0202e-03,  1.1749e-02,\n",
      "          1.5621e-02,  1.0153e-04,  1.9559e-02,  3.5233e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.1960e-02,  1.5552e-02,  0.0000e+00,  6.9382e-04,\n",
      "          0.0000e+00,  3.5338e-02,  1.8610e-03,  7.1975e-04,  1.2720e-02,\n",
      "          3.0233e-03,  1.0914e-03,  3.3577e-02,  0.0000e+00,  2.3360e-03,\n",
      "          0.0000e+00,  3.2042e-02,  0.0000e+00,  0.0000e+00,  5.4082e-05,\n",
      "          5.6138e-04,  0.0000e+00,  1.0731e-02,  4.7058e-02,  8.8494e-03,\n",
      "          0.0000e+00,  2.5661e-02,  1.4869e-03,  1.8018e-03,  0.0000e+00,\n",
      "          4.6964e-04,  2.9838e-02,  0.0000e+00,  0.0000e+00,  6.7277e-03,\n",
      "          2.5180e-03,  7.8466e-02,  4.1802e-02,  1.1485e-02,  2.0950e-02,\n",
      "          0.0000e+00,  6.0563e-03,  1.4947e-02,  4.9327e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.6543e-02,  5.4530e-02,  7.2824e-03,  7.4564e-03,\n",
      "          1.4639e-02,  6.6960e-02,  9.4968e-03,  4.4687e-02],\n",
      "        [ 6.6308e-02,  3.1309e-02,  2.1934e-03,  6.2237e-03,  5.4582e-02,\n",
      "          1.3788e-02,  1.1289e-02,  1.6494e-03,  0.0000e+00,  9.8921e-05,\n",
      "          1.8309e-02,  1.6017e-02,  2.5143e-02,  1.9924e-03,  7.4109e-04,\n",
      "          0.0000e+00,  5.9004e-02,  4.5339e-02,  1.8632e-02,  0.0000e+00,\n",
      "          3.4929e-02,  1.3069e-02,  1.0536e-02,  4.9920e-03,  1.1575e-02,\n",
      "          1.5746e-02,  1.0774e-04,  1.9945e-02,  3.5629e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.2187e-02,  1.5205e-02,  0.0000e+00,  6.6939e-04,\n",
      "          0.0000e+00,  3.5525e-02,  1.8187e-03,  7.1759e-04,  1.2491e-02,\n",
      "          2.9881e-03,  1.1007e-03,  3.3922e-02,  0.0000e+00,  2.3219e-03,\n",
      "          0.0000e+00,  3.2344e-02,  0.0000e+00,  0.0000e+00,  5.2152e-05,\n",
      "          5.4181e-04,  0.0000e+00,  1.0710e-02,  4.7471e-02,  8.8861e-03,\n",
      "          0.0000e+00,  2.5866e-02,  1.4525e-03,  1.8124e-03,  0.0000e+00,\n",
      "          4.5437e-04,  3.0078e-02,  0.0000e+00,  0.0000e+00,  6.8464e-03,\n",
      "          2.4696e-03,  7.8133e-02,  4.1706e-02,  1.1201e-02,  2.1027e-02,\n",
      "          0.0000e+00,  5.8639e-03,  1.4816e-02,  5.0191e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.6722e-02,  5.4242e-02,  7.1665e-03,  7.2482e-03,\n",
      "          1.4721e-02,  6.6923e-02,  9.3694e-03,  4.4966e-02],\n",
      "        [-1.3939e-01, -4.3495e-02, -3.3694e-03,  5.7270e-03, -8.8250e-02,\n",
      "         -4.4087e-02, -2.0842e-02, -2.4809e-03,  0.0000e+00, -9.7985e-04,\n",
      "         -3.9915e-02, -2.4120e-02, -9.8628e-02, -1.2572e-02,  8.1931e-04,\n",
      "          0.0000e+00, -1.5104e-01, -1.4739e-01, -2.9920e-02,  0.0000e+00,\n",
      "         -4.5678e-02, -2.6977e-02, -1.9445e-02, -2.7016e-02, -1.3726e-02,\n",
      "          1.5987e-02,  1.2163e-04, -3.5768e-02, -9.3426e-02,  0.0000e+00,\n",
      "          0.0000e+00, -1.1220e-01, -9.8386e-03,  0.0000e+00,  7.0661e-04,\n",
      "          0.0000e+00, -8.4164e-02, -3.1018e-03,  7.8973e-04, -2.0722e-02,\n",
      "          3.2211e-03, -1.1035e-02, -7.8654e-02,  0.0000e+00,  2.5101e-03,\n",
      "          0.0000e+00, -9.1247e-02,  0.0000e+00,  0.0000e+00,  5.5126e-05,\n",
      "         -1.1121e-03,  0.0000e+00,  7.3546e-03, -6.5307e-02,  9.7287e-03,\n",
      "          0.0000e+00, -8.5276e-02, -1.4351e-02,  4.2552e-04,  0.0000e+00,\n",
      "          4.8111e-04, -1.0970e-01,  0.0000e+00,  0.0000e+00, -3.2425e-02,\n",
      "         -1.4714e-02, -2.2446e-01, -1.2833e-01, -1.8775e-02, -1.5217e-02,\n",
      "          0.0000e+00, -9.0407e-03, -9.2457e-02,  5.5491e-03,  0.0000e+00,\n",
      "          0.0000e+00, -3.9982e-02, -1.2156e-01,  2.9577e-03, -7.4958e-03,\n",
      "          8.1140e-03, -1.3151e-01, -1.3826e-02, -7.5025e-02],\n",
      "        [ 7.3978e-02,  3.4626e-02,  2.3599e-03,  7.1511e-03,  6.0067e-02,\n",
      "          1.5072e-02,  1.2343e-02,  1.8197e-03,  0.0000e+00,  1.0995e-04,\n",
      "          2.0099e-02,  1.8163e-02,  2.8263e-02,  2.1633e-03,  8.3589e-04,\n",
      "          0.0000e+00,  6.5039e-02,  4.9974e-02,  2.0946e-02,  0.0000e+00,\n",
      "          3.9155e-02,  1.4784e-02,  1.1482e-02,  5.5016e-03,  1.3008e-02,\n",
      "          1.7592e-02,  1.1476e-04,  2.1780e-02,  3.9388e-02,  0.0000e+00,\n",
      "          0.0000e+00,  5.7706e-02,  1.7418e-02,  0.0000e+00,  7.7241e-04,\n",
      "          0.0000e+00,  3.9378e-02,  2.0900e-03,  7.7558e-04,  1.4164e-02,\n",
      "          3.4677e-03,  1.2048e-03,  3.7265e-02,  0.0000e+00,  2.6361e-03,\n",
      "          0.0000e+00,  3.5597e-02,  0.0000e+00,  0.0000e+00,  6.0314e-05,\n",
      "          6.3008e-04,  0.0000e+00,  1.2224e-02,  5.2688e-02,  9.8447e-03,\n",
      "          0.0000e+00,  2.8313e-02,  1.6303e-03,  1.9593e-03,  0.0000e+00,\n",
      "          5.2169e-04,  3.3231e-02,  0.0000e+00,  0.0000e+00,  7.4494e-03,\n",
      "          2.7439e-03,  8.6996e-02,  4.6546e-02,  1.2762e-02,  2.3374e-02,\n",
      "          0.0000e+00,  6.7674e-03,  1.6477e-02,  5.6307e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.8529e-02,  6.0461e-02,  8.2585e-03,  8.2909e-03,\n",
      "          1.6614e-02,  7.4225e-02,  1.0425e-02,  4.9779e-02]])\n",
      "tensor([ 0.4588, -0.7917, -0.6854,  0.4574, -0.6982,  0.5709,  0.4593,  0.4582,\n",
      "        -0.7408,  0.5114])\n"
     ]
    }
   ],
   "source": [
    "for elem in net.parameters():\n",
    "    print(elem.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected 1 arguments, got 0 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b30104b2d94e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected 1 arguments, got 0 instead"
     ]
    }
   ],
   "source": [
    "outputs.grad_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ed28f693d1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhvp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "grads = torch.autograd.grad(output, params, create_graph = True)\n",
    "dot = 0\n",
    "for i in range(len(grads)):\n",
    "    dot += grads[i].mul(vector[i]).sum()\n",
    "hvp = torch.autograd.grad(dot, params, retain_graph = True)\n",
    "return hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-98eaee69e2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/optimization/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_filename\u001b[0;34m(cls, manager, handle, size)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstorage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_decref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0mshared_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageWeakRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_decref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Y = []\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            Y.append(avg_loss / 100)\n",
    "            avg_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "plt.plot(range(len(Y)), Y)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of iteration (log)')\n",
    "plt.ylabel('<Loss>_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "Z = []\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            Z.append(avg_loss / 100)\n",
    "            avg_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.LBFGS(net.parameters(), lr=0.001)\n",
    "\n",
    "A = []\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        def closure():\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "            \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            A.append(avg_loss / 100)\n",
    "            avg_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "inputs, labels = data\n",
    "optimizer = CubicNewton(net.parameters(), net(inputs), lr=0.001)\n",
    "\n",
    "B = []\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        def closure():\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "            \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            B.append(avg_loss / 100)\n",
    "            avg_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from nielish import SCR\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "inputs, labels = data\n",
    "optimizer = SCR(net.parameters(), lr=0.001)\n",
    "\n",
    "C = []\n",
    "\n",
    "for epoch in range(0):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        def closure():\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        optimizer.step(closure)\n",
    "            \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            C.append(avg_loss / 100)\n",
    "            avg_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(Y)), Y)\n",
    "plt.plot(range(len(Z)), Z)\n",
    "plt.plot(range(len(A)), A)\n",
    "plt.plot(range(len(B)), B)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of iteration (log)')\n",
    "plt.ylabel('<Loss>_100')\n",
    "plt.legend(['Adam', 'SGD', 'LBFGS', 'Cubic-Newton'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net-Adam.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
